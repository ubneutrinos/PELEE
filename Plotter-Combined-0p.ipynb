{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING BDT?\n",
    "USEBDT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cale to MCC8 CV?\n",
    "MCC8WEIGHTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "fold = ls.fold\n",
    "fold_run2 = 'nuselection'\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "R3BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_G1_beam_good_reco2_1e19'\n",
    "#R3EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G_all_reco2'\n",
    "R3EXT = 'ext_run3'\n",
    "R3NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "R3NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3NCPI0  = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "R3CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "R3CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run3_reco2_reco2'\n",
    "R3CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "R3NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "R3NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "\n",
    "#ls.ntuple_path = \"/Users/cerati/Notebooks/PELEE/root_files/0218/\"\n",
    "\n",
    "ur3mc = uproot.open(ls.ntuple_path+ls.RUN3+R3NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nue = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3data = uproot.open(ls.ntuple_path+ls.RUN3+R3BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ext = uproot.open(ls.ntuple_path+ls.RUN3+R3EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3dirt = uproot.open(ls.ntuple_path+ls.RUN3+R3DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3lee = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3cccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R2NU = \"prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run2_reco2_D1D2_reco2\"\n",
    "R2NUE = \"prodgenie_bnb_intrinsic_nue_overlay_run2_v08_00_00_35_run2a_reco2_reco2\"\n",
    "R2EXT = 'ext_run2'\n",
    "\n",
    "ur2mc = uproot.open(ls.ntuple_path+ls.RUN2+R2NU+\".root\")[fold_run2][tree]\n",
    "ur2nue = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+\".root\")[fold_run2][tree]\n",
    "ur2lee = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+\".root\")[fold_run2][tree]\n",
    "ur2ext = uproot.open(ls.ntuple_path+ls.RUN2+R2EXT+\".root\")[fold_run2][tree]\n",
    "\n",
    "R1BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_beam_good_reco2_5e19'\n",
    "#R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_all_reco2'\n",
    "#R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_C2_D1_D2_E1_E2_all_reco2' #Run1 + Run2\n",
    "R1EXT = 'ext_run1'\n",
    "R1NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "R1NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1NCPI0  = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "R1CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "R1CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run1_reco2_reco2'\n",
    "R1CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    \n",
    "ur1mc = uproot.open(ls.ntuple_path+ls.RUN1+R1NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nue = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1data = uproot.open(ls.ntuple_path+ls.RUN1+R1BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ext = uproot.open(ls.ntuple_path+ls.RUN1+R1EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1dirt = uproot.open(ls.ntuple_path+ls.RUN1+R1DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1lee = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1cccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "variables = [\n",
    "    \"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\",\n",
    "    \"shr_tkfit_dedx_U\",\"shr_tkfit_dedx_V\",\"shr_tkfit_dedx_Y\",\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "    #\"shr_energy_tot\", \n",
    "    \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    \"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    #\"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\"CosmicDirAll3D\",\"CosmicIPAll3D\",\n",
    "    \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "    #\"trk_pfp_id\",\n",
    "    \"shrmoliereavg\",\"shrmoliererms\",\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "    \"trkshrhitdist2\", # \"trkshrhitdist0\",\"trkshrhitdist1\", distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    #\"pi0_energy2_Y\", # pi0 tagger variables\n",
    "    \"_opfilter_pe_beam\", \"_opfilter_pe_veto\", # did the event pass the common optical filter (for MC only)\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "    \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"shr_tkfit_nhits_Y\",\"shr_tkfit_nhits_U\",\"shr_tkfit_nhits_V\",\n",
    "    \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_U\",\"shr_tkfit_2cm_nhits_V\",\n",
    "    \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_U\",\"shr_tkfit_gap10_nhits_V\",\n",
    "      #added for 1e0p\n",
    "    \"secondshower_Y_nhit\", 'secondshower_U_nhit', 'secondshower_V_nhit',\n",
    "    \"secondshower_Y_dir\", \"secondshower_V_dir\", \"secondshower_U_dir\",\n",
    "    \"shrclusdir2\",\"shrclusdir1\",\"shrclusdir0\",\n",
    "    \"secondshower_Y_vtxdist\",'secondshower_U_vtxdist', 'secondshower_V_vtxdist', \n",
    "    \"secondshower_Y_dot\",'secondshower_U_dot', 'secondshower_V_dot', \n",
    "    \"merge_bestdist\",\n",
    "    \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_V\",\"shr_tkfit_2cm_nhits_U\",\n",
    "    \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_V\",\"shr_tkfit_gap10_nhits_U\",\n",
    "    \"CosmicIPAll3D\",\"CosmicDirAll3D\",\n",
    "    \"shrMCSMom\",\"DeltaRMS2h\",\"shrPCA1CMed_5cm\",\"CylFrac2h_1cm\",\n",
    "    \"isVtxInFiducial\",\"truthFiducial\"\n",
    "]\n",
    "#make the list unique\n",
    "variables = list(set(variables))\n",
    "print(variables)\n",
    "\n",
    "variables.remove(\"_closestNuCosmicDist\")\n",
    "variables.remove(\"crtveto\")\n",
    "variables.remove(\"crthitpe\")\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "\n",
    "r3nue = ur3nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3mc = ur3mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r3ncpi0 = ur3ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccpi0 = ur3ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccnopi = ur3ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3cccpi = ur3cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ncnopi = ur3ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3nccpi = ur3nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3data = ur3data.pandas.df(variables, flatten=False)\n",
    "r3ext = ur3ext.pandas.df(variables, flatten=False)\n",
    "r3dirt = ur3dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3lee = ur3lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r3lee[\"is_signal\"] = r3lee[\"category\"] == 10\n",
    "r3data[\"is_signal\"] = r3data[\"category\"] == 10\n",
    "r3nue[\"is_signal\"] = r3nue[\"category\"] == 10\n",
    "r3mc[\"is_signal\"] = r3mc[\"category\"] == 10\n",
    "r3dirt[\"is_signal\"] = r3dirt[\"category\"] == 10\n",
    "r3ext[\"is_signal\"] = r3ext[\"category\"] == 10\n",
    "r3ncpi0[\"is_signal\"] = r3ncpi0[\"category\"] == 10\n",
    "r3ccpi0[\"is_signal\"] = r3ccpi0[\"category\"] == 10\n",
    "r3ccnopi[\"is_signal\"] = r3ccnopi[\"category\"] == 10\n",
    "r3cccpi[\"is_signal\"] = r3cccpi[\"category\"] == 10\n",
    "r3ncnopi[\"is_signal\"] = r3ncnopi[\"category\"] == 10\n",
    "r3nccpi[\"is_signal\"] = r3nccpi[\"category\"] == 10\n",
    "r3lee.loc[r3lee['category'] == 1, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 10, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur3lee,ur3mc,ur3ncpi0,ur3ccpi0,ur3ccnopi,ur3cccpi,ur3ncnopi,ur3nccpi,ur3nue,ur3ext,ur3data,ur3dirt]\n",
    "df_v = [r3lee,r3mc,r3ncpi0,r3ccpi0,r3ccnopi,r3cccpi,r3ncnopi,r3nccpi,r3nue,r3ext,r3data,r3dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "\n",
    "if (USEBDT == True):\n",
    "    train_r3ccpi0, r3ccpi0 = train_test_split(r3ccpi0, test_size=0.5, random_state=1990)   \n",
    "    \n",
    "r1nue = ur1nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1mc = ur1mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r1ncpi0 = ur1ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccpi0 = ur1ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccnopi = ur1ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1cccpi = ur1cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ncnopi = ur1ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1nccpi = ur1nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1data = ur1data.pandas.df(variables, flatten=False)\n",
    "r1ext = ur1ext.pandas.df(variables, flatten=False)\n",
    "r1dirt = ur1dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1lee = ur1lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r1lee[\"is_signal\"] = r1lee[\"category\"] == 10\n",
    "r1data[\"is_signal\"] = r1data[\"category\"] == 10\n",
    "r1nue[\"is_signal\"] = r1nue[\"category\"] == 10\n",
    "r1mc[\"is_signal\"] = r1mc[\"category\"] == 10\n",
    "r1dirt[\"is_signal\"] = r1dirt[\"category\"] == 10\n",
    "r1ext[\"is_signal\"] = r1ext[\"category\"] == 10\n",
    "r1ncpi0[\"is_signal\"] = r1ncpi0[\"category\"] == 10\n",
    "r1ccpi0[\"is_signal\"] = r1ccpi0[\"category\"] == 10\n",
    "r1ccnopi[\"is_signal\"] = r1ccnopi[\"category\"] == 10\n",
    "r1cccpi[\"is_signal\"] = r1cccpi[\"category\"] == 10\n",
    "r1ncnopi[\"is_signal\"] = r1ncnopi[\"category\"] == 10\n",
    "r1nccpi[\"is_signal\"] = r1nccpi[\"category\"] == 10\n",
    "r1lee.loc[r1lee['category'] == 1, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 10, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur1lee,ur1mc,ur1ncpi0,ur1ccpi0,ur1ccnopi,ur1cccpi,ur1ncnopi,ur1nccpi,ur1nue,ur1ext,ur1data,ur1dirt]\n",
    "df_v = [r1lee,r1mc,r1ncpi0,r1ccpi0,r1ccnopi,r1cccpi,r1ncnopi,r1nccpi,r1nue,r1ext,r1data,r1dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "\n",
    "\n",
    "r2nue = ur2nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r2mc = ur2mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r2lee = ur2lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "r2ext = ur2ext.pandas.df(variables, flatten=False)\n",
    "\n",
    "r2lee[\"is_signal\"] = r2lee[\"category\"] == 10\n",
    "r2nue[\"is_signal\"] = r2nue[\"category\"] == 10\n",
    "r2mc[\"is_signal\"] = r2mc[\"category\"] == 10\n",
    "r2ext[\"is_signal\"] = r2ext[\"category\"] == 10\n",
    "r2lee.loc[r2lee['category'] == 1, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 10, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur2lee,ur2mc,ur2nue,ur2ext]\n",
    "df_v = [r2lee,r2mc,r2nue,r2ext]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    \n",
    "#if (USEBDT == True):\n",
    "   # train_ext_bnb, r2ext = train_test_split(r2ext, test_size=0.5, random_state=1990)\n",
    "    \n",
    "nue = pd.concat([r1nue,r2nue,r3nue],ignore_index=True)\n",
    "#nue = pd.concat([r3nue,r1nue],ignore_index=True)\n",
    "mc = pd.concat([r3mc,r2mc,r1mc],ignore_index=True)\n",
    "#mc = pd.concat([r3mc,r1mc],ignore_index=True)\n",
    "ncpi0 = pd.concat([r3ncpi0,r1ncpi0],ignore_index=True)\n",
    "ccpi0 = pd.concat([r3ccpi0,r1ccpi0],ignore_index=True)\n",
    "ccnopi = pd.concat([r3ccnopi,r1ccnopi],ignore_index=True)\n",
    "cccpi = pd.concat([r3cccpi,r1cccpi],ignore_index=True)\n",
    "ncnopi = pd.concat([r3ncnopi,r1ncnopi],ignore_index=True)\n",
    "nccpi = pd.concat([r3nccpi,r1nccpi],ignore_index=True)\n",
    "data = pd.concat([r3data,r1data],ignore_index=True)\n",
    "ext = pd.concat([r3ext,r1ext,r2ext],ignore_index=True) \n",
    "dirt = pd.concat([r3dirt,r1dirt],ignore_index=True)\n",
    "lee = pd.concat([r1lee,r2lee,r3lee],ignore_index=True)\n",
    "#lee = pd.concat([r3lee,r1lee],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    #df['weightSpline']  = df['weightSpline']  * df['weightTune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust from MCC9 CV to MCC8 CV\n",
    "\n",
    "if (MCC8WEIGHTS == True):\n",
    "\n",
    "    # scaling for QE\n",
    "    CV_bins = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,5.0]\n",
    "    CV_scaling = [2.5,2.0,1.7,1.45,1.3,1.25,1.175,1.15,1.14,1.1]\n",
    "    # scaling for RES\n",
    "\n",
    "    mc.loc[ (mc['interaction'] == 10), 'weightSpline' ] = 2 * mc['weightSpline']\n",
    "    ncpi0.loc[ (ncpi0['interaction'] == 10), 'weightSpline' ] = 2 * ncpi0['weightSpline']\n",
    "    ccpi0.loc[ (ccpi0['interaction'] == 10), 'weightSpline' ] = 2 * ccpi0['weightSpline']\n",
    "    ccnopi.loc[ (ccnopi['interaction'] == 10), 'weightSpline' ] = 2 * ccnopi['weightSpline']\n",
    "    cccpi.loc[ (cccpi['interaction'] == 10), 'weightSpline' ] = 2 * cccpi['weightSpline']\n",
    "    ncnopi.loc[ (ncnopi['interaction'] == 10), 'weightSpline' ] = 2 * ncnopi['weightSpline']\n",
    "    nccpi.loc[ (nccpi['interaction'] == 10), 'weightSpline' ] = 2 * nccpi['weightSpline']\n",
    "    nue.loc[ (nue['interaction'] == 10), 'weightSpline' ] = 2 * nue['weightSpline']\n",
    "    lee.loc[ (lee['interaction'] == 10), 'weightSpline' ] = 2 * lee['weightSpline']\n",
    "    dirt.loc[ (dirt['interaction'] == 10), 'weightSpline' ] = 2 * dirt['weightSpline']\n",
    "\n",
    "    for i, CV_bin in enumerate(CV_bins):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        mc.loc[ (mc['nu_e'] > CV_bins[i-1]) & (mc['nu_e'] < CV_bins[i]) & (mc['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * mc['weightSpline']\n",
    "        nue.loc[ (nue['nu_e'] > CV_bins[i-1]) & (nue['nu_e'] < CV_bins[i]) & (nue['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nue['weightSpline']\n",
    "        ncpi0.loc[ (nc['nu_e'] > CV_bins[i-1]) & (ncpi0['nu_e'] < CV_bins[i]) & (ncpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncpi0['weightSpline']\n",
    "        ccpi0.loc[ (ccpi0['nu_e'] > CV_bins[i-1]) & (ccpi0['nu_e'] < CV_bins[i]) & (ccpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccpi0['weightSpline']\n",
    "        ccnopi.loc[ (ccnopi['nu_e'] > CV_bins[i-1]) & (ccnopi['nu_e'] < CV_bins[i]) & (ccnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccnopi['weightSpline']\n",
    "        cccpi.loc[ (cccpi['nu_e'] > CV_bins[i-1]) & (cccpi['nu_e'] < CV_bins[i]) & (cccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * cccpi['weightSpline']\n",
    "        ncnopi.loc[ (ncnopi['nu_e'] > CV_bins[i-1]) & (ncnopi['nu_e'] < CV_bins[i]) & (ncnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncnopi['weightSpline']\n",
    "        nccpi.loc[ (nccpi['nu_e'] > CV_bins[i-1]) & (nccpi['nu_e'] < CV_bins[i]) & (nccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nccpi['weightSpline']\n",
    "        lee.loc[ (lee['nu_e'] > CV_bins[i-1]) & (lee['nu_e'] < CV_bins[i]) & (lee['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * lee['weightSpline']\n",
    "        dirt.loc[ (dirt['nu_e'] > CV_bins[i-1]) & (dirt['nu_e'] < CV_bins[i]) & (dirt['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * dirt['weightSpline']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "#df_v = [lee,mc,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    # and the 2d angle difference\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])\n",
    "    df['anglediff_V'] = np.abs(df['secondshower_V_dir']-df['shrclusdir1'])\n",
    "    df['anglediff_U'] = np.abs(df['secondshower_U_dir']-df['shrclusdir0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df['shr_tkfit_nhits_tot'] = (df['shr_tkfit_nhits_Y']+df['shr_tkfit_nhits_U']+df['shr_tkfit_nhits_V'])\n",
    "    df['shr_tkfit_dedx_avg'] = (df['shr_tkfit_nhits_Y']*df['shr_tkfit_dedx_Y'] + df['shr_tkfit_nhits_U']*df['shr_tkfit_dedx_U'] + df['shr_tkfit_nhits_V']*df['shr_tkfit_dedx_V'])/df['shr_tkfit_nhits_tot']\n",
    "    df['shr_tkfit_2cm_nhits_tot'] = (df['shr_tkfit_2cm_nhits_Y']+df['shr_tkfit_2cm_nhits_U']+df['shr_tkfit_2cm_nhits_V'])\n",
    "    df['shr_tkfit_2cm_dedx_avg'] = (df['shr_tkfit_2cm_nhits_Y']*df['shr_tkfit_2cm_dedx_Y'] + df['shr_tkfit_2cm_nhits_U']*df['shr_tkfit_2cm_dedx_U'] + df['shr_tkfit_2cm_nhits_V']*df['shr_tkfit_2cm_dedx_V'])/df['shr_tkfit_2cm_nhits_tot']\n",
    "    df['shr_tkfit_gap10_nhits_tot'] = (df['shr_tkfit_gap10_nhits_Y']+df['shr_tkfit_gap10_nhits_U']+df['shr_tkfit_gap10_nhits_V'])\n",
    "    df['shr_tkfit_gap10_dedx_avg'] = (df['shr_tkfit_gap10_nhits_Y']*df['shr_tkfit_gap10_dedx_Y'] + df['shr_tkfit_gap10_nhits_U']*df['shr_tkfit_gap10_dedx_U'] + df['shr_tkfit_gap10_nhits_V']*df['shr_tkfit_gap10_dedx_V'])/df['shr_tkfit_gap10_nhits_tot']\n",
    "    df.loc[:,'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_nhits_U']>df['shr_tkfit_nhits_Y']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_Y']) & (df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_U']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_V']\n",
    "    df.loc[:,'shr_tkfit_gap10_dedx_max'] = df['shr_tkfit_gap10_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_gap10_nhits_U']>df['shr_tkfit_gap10_nhits_Y']),'shr_tkfit_gap10_dedx_max'] = df['shr_tkfit_gap10_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_gap10_nhits_V']>df['shr_tkfit_gap10_nhits_Y']) & (df['shr_tkfit_gap10_nhits_V']>df['shr_tkfit_gap10_nhits_U']),'shr_tkfit_gap10_dedx_max'] = df['shr_tkfit_gap10_dedx_V']\n",
    "    df.loc[:,'shr_tkfit_2cm_dedx_max'] = df['shr_tkfit_2cm_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_2cm_nhits_U']>df['shr_tkfit_2cm_nhits_Y']),'shr_tkfit_2cm_dedx_max'] = df['shr_tkfit_2cm_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_2cm_nhits_V']>df['shr_tkfit_2cm_nhits_Y']) & (df['shr_tkfit_2cm_nhits_V']>df['shr_tkfit_2cm_nhits_U']),'shr_tkfit_2cm_dedx_max'] = df['shr_tkfit_2cm_dedx_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INTERCEPT = 0.0\n",
    "SLOPE = 0.83\n",
    "\n",
    "# define some energy-related variables\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"reco_e\"] = (df[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + df[\"trk_energy_tot\"]\n",
    "    df[\"reco_e_qe\"] = 0.938*((df[\"shr_energy\"]+INTERCEPT)/SLOPE)/(0.938 - ((df[\"shr_energy\"]+INTERCEPT)/SLOPE)*(1-np.cos(df[\"shr_theta\"])))\n",
    "    df[\"reco_e_rqe\"] = df[\"reco_e_qe\"]/df[\"reco_e\"]\n",
    "\n",
    "# and a way to filter out data\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"bnbdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "    df[\"extdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "data[\"bnbdata\"] = np.ones_like(data[\"shr_energy\"])\n",
    "ext[\"extdata\"] = np.ones_like(ext[\"shr_energy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double-counting of events out of FV in the NC/CC pi0 samples\n",
    "# not needed anymore since we improved matching with filtered samples\n",
    "#ncpi0 = ncpi0.query('category != 5')\n",
    "#ccpi0 = ccpi0.query('category != 5')\n",
    "#ccnopi = ccnopi.query('category != 5')\n",
    "#nccpi = nccpi.query('category != 5')\n",
    "#ncnopi = ncnopi.query('category != 5')\n",
    "\n",
    "## avoid recycling unbiased ext events (i.e. selecting a slice with little nu content from these samples)\n",
    "ccnopi = ccnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "cccpi = cccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "ncnopi = ncnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "nccpi = nccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "\n",
    "# add back the cosmic category, for background only\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p train variables\n",
    "TRAINVAR = [#'tksh_angle','trkpid',\n",
    "            #'shrmoliererms',\n",
    "            'shrmoliereavg','shr_score', \"trkfit\",\"subcluster\",\n",
    "            \"CosmicIPAll3D\",\"CosmicDirAll3D\",\n",
    "            'secondshower_Y_nhit','secondshower_Y_vtxdist','secondshower_Y_dot','anglediff_Y',\n",
    "            'secondshower_V_nhit','secondshower_V_vtxdist','secondshower_V_dot','anglediff_V',\n",
    "            'secondshower_U_nhit','secondshower_U_vtxdist','secondshower_U_dot','anglediff_U',\n",
    "            \"shr_tkfit_2cm_dedx_U\", \"shr_tkfit_2cm_dedx_V\", \"shr_tkfit_2cm_dedx_Y\",\n",
    "            \"shr_tkfit_gap10_dedx_U\", \"shr_tkfit_gap10_dedx_V\", \"shr_tkfit_gap10_dedx_Y\",\n",
    "            \"shrMCSMom\", \"DeltaRMS2h\", \"shrPCA1CMed_5cm\", \"CylFrac2h_1cm\"\n",
    "            #\"shr_tkfit_gap10_nhits_tot\",\"shr_tkfit_2cm_nhits_tot\",\n",
    "            #\"n_showers_contained\",\"tksh_distance\",\n",
    "            #\"trkshrhitdist2\",\n",
    "            #\"hits_ratio\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Np variables to be trained on\n",
    "TRAINVAR = [\"shr_score\",\"tksh_distance\",\"tksh_angle\",\n",
    "            \"shr_tkfit_dedx_max\",\n",
    "            \"trkfit\",\"trkpid\",\n",
    "            \"subcluster\",\"shrmoliereavg\",\n",
    "            \"trkshrhitdist2\",\"hits_ratio\",\n",
    "            \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"anglediff_Y\",\n",
    "            \"CosmicIPAll3D\",\"CosmicDirAll3D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcI43ileYJ9P"
   },
   "outputs": [],
   "source": [
    "LABELS =  ['bkg','pi0','nonpi0']\n",
    "#LABELS =  [\"bkg\"]\n",
    "\n",
    "if (USEBDT == True):\n",
    "    for label, bkg_query in zip(LABELS, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'mcs_noext_200326/'+'booster_%s_0304_extnumi_vx.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            mc[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(mc[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nue[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nue[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ext[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ext[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            data[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(data[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            dirt[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(dirt[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            lee[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(lee[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            cccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(cccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbdt_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    \"ncpi0\": ncpi0,\n",
    "    \"ccpi0\": ccpi0,\n",
    "    \"ccnopi\": ccnopi,\n",
    "    \"cccpi\": cccpi,\n",
    "    \"ncnopi\": ncnopi,\n",
    "    \"nccpi\": nccpi,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "#scaling = 101.0/4.21 #0218\n",
    "\n",
    "scaling = 101.0/4.84 #0304\n",
    "\n",
    "#scaling = 69.6/4.84 #0304\n",
    "#scaling = 125.0/4.84 #0304\n",
    "#scaling = 1\n",
    "\n",
    "SPLIT = 1.0\n",
    "if (USEBDT == True):\n",
    "    SPLIT = 1.48\n",
    "\n",
    "#''' 0304\n",
    "weights = {\n",
    "    \"mc\": 1.32e-02 * scaling, #Run1,2,3: 1.32e-2; Run1,3: 1.83e-2\n",
    "    \"ext\": 3.97e-02 * scaling, #Run1,2,3: 3.97e-02; Run1,3: 7.16e-02\n",
    "    #\"ext\": 7.16e-02 *scaling, #run 1,3\n",
    "    #\"ext\": 5.11e-02 * scaling, #run1,2,3; split run 2\n",
    "    \"nue\": 2.73e-04 * scaling, #Run1,2,3: 2.73e-4; Run1,3: 4.18e-4\n",
    "    \"lee\": 2.73e-04 * scaling,\n",
    "    \"dirt\": 7.48e-02 * scaling,\n",
    "    \"ncpi0\": 9.77e-03 * scaling,\n",
    "    \"ccpi0\": 4.87e-03 * SPLIT * scaling,\n",
    "    \"ncnopi\": 4.61e-03 * scaling,\n",
    "    \"nccpi\": 2.12e-03 * scaling,\n",
    "    \"ccnopi\": 5.33e-03 * scaling,\n",
    "    \"cccpi\": 4.26e-03 * scaling,\n",
    "}\n",
    "pot = 4.84e19*scaling\n",
    "#'''\n",
    "my_plotter = plotter.Plotter(samples, weights, pot=pot)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nue preselection\n",
    "PRESQ = 'nslice == 1'\n",
    "PRESQ += ' and selected == 1'\n",
    "PRESQ += ' and shr_energy_tot_cali > 0.07'\n",
    "PRESQ += ' and ( (_opfilter_pe_beam > 0 and _opfilter_pe_veto < 20) or bnbdata == 1 or extdata == 1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1eNp preselection\n",
    "NPPRESQ = PRESQ\n",
    "NPPRESQ += ' and n_tracks_contained > 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very loose box cuts\n",
    "NPVLCUTQ = NPPRESQ\n",
    "NPVLCUTQ += ' and CosmicIPAll3D > 10.'\n",
    "NPVLCUTQ += ' and trkpid < 0.25'\n",
    "NPVLCUTQ += ' and hits_ratio > 0.5'\n",
    "NPVLCUTQ += ' and trkfit < 0.90'\n",
    "NPVLCUTQ += ' and n_showers_contained == 1'\n",
    "NPVLCUTQ += ' and tksh_distance < 10.0'\n",
    "NPVLCUTQ += ' and tksh_angle > -0.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose box cuts\n",
    "NPLCUTQ = NPPRESQ\n",
    "NPLCUTQ += ' and CosmicIPAll3D > 10.'\n",
    "NPLCUTQ += ' and trkpid < 0.02'\n",
    "NPLCUTQ += ' and hits_ratio > 0.50'\n",
    "NPLCUTQ += ' and shrmoliereavg < 9'\n",
    "NPLCUTQ += ' and subcluster > 4'\n",
    "NPLCUTQ += ' and trkfit < 0.65'\n",
    "NPLCUTQ += ' and n_showers_contained == 1'\n",
    "NPLCUTQ += ' and tksh_distance < 6.0'\n",
    "NPLCUTQ += ' and (shr_tkfit_nhits_tot > 1 and shr_tkfit_dedx_max > 0.5 and shr_tkfit_dedx_max < 5.5)'\n",
    "NPLCUTQ += ' and secondshower_Y_nhit < 50'\n",
    "NPLCUTQ += ' and tksh_angle > -0.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tight box cuts\n",
    "NPTCUTQ = NPLCUTQ\n",
    "NPTCUTQ += ' and CosmicIPAll3D > 30.'\n",
    "NPTCUTQ += ' and CosmicDirAll3D > -0.98 and CosmicDirAll3D < 0.98'\n",
    "NPTCUTQ += ' and trkpid < 0.02'\n",
    "NPTCUTQ += ' and hits_ratio > 0.65'\n",
    "NPTCUTQ += ' and shr_score < 0.25'\n",
    "NPTCUTQ += ' and shrmoliereavg > 2 and shrmoliereavg < 10'\n",
    "NPTCUTQ += ' and subcluster > 7'\n",
    "NPTCUTQ += ' and trkfit < 0.70'\n",
    "NPTCUTQ += ' and n_showers_contained == 1'\n",
    "NPTCUTQ += ' and tksh_distance < 4.0'\n",
    "NPTCUTQ += ' and trkshrhitdist2 < 1.5'\n",
    "NPTCUTQ += ' and (shr_tkfit_nhits_tot > 1 and shr_tkfit_dedx_max > 1.0 and shr_tkfit_dedx_max < 3.8)'\n",
    "NPTCUTQ += ' and (secondshower_Y_nhit<=8 or secondshower_Y_dot<=0.8 or anglediff_Y<=40 or secondshower_Y_vtxdist>=100)'\n",
    "NPTCUTQ += ' and secondshower_Y_nhit < 30'\n",
    "NPTCUTQ += ' and tksh_angle > -0.9 and tksh_angle < 0.70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Np BDT cuts\n",
    "# 0304 extnumi, pi0 and nonpi0\n",
    "BDTCQ = NPLCUTQ\n",
    "BDTCQ += ' and pi0_score > 0.67 and nonpi0_score > 0.70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Np Define actual selection\n",
    "QUERY = NPTCUTQ\n",
    "# in case you do not want to look at the data\n",
    "QUERY += ' and bnbdata==0'\n",
    "# in case you want to apply the CRT veto\n",
    "#if ISRUN3: QUERY += ' and (crtveto!=1) and (_closestNuCosmicDist > 20.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(QUERY)[[\"run\",\"evt\",\"reco_e\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output files based on selection\n",
    "#uproot_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "#fname_v = [NUE,NU,NCPI0,CCPI0,CCNOPI,CCCPI,NCNOPI,NCCPI,NUE,EXT,BNB,DRT]\n",
    "\n",
    "fname_v = [R3BNB,R3EXT,R3NU,R3NUE,R3DRT,R3NCPI0,R3CCPI0,R3CCNOPI,R3CCCPI,R3NCNOPI,R3NCCPI,\\\n",
    "           R2NU,R2NUE,\\\n",
    "           R1BNB,R1EXT,R1NU,R1NUE,R1DRT,R1NCPI0,R1CCPI0,R1CCNOPI,R1CCCPI,R1NCNOPI,R1NCCPI]\n",
    "\n",
    "dfsave_v = [data,ext,mc,nue,dirt,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,\\\n",
    "            mc,nue,\\\n",
    "           data,ext,mc,nue,dirt,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi]\n",
    "\n",
    "NU_Q = \"~(abs(nu_pdg) == 12 & ccnc == 0)\"\n",
    "NU_Q += \" & ~(mcf_np0==1 & mcf_nmp==0 & mcf_nmm==0 & mcf_nem==0 & mcf_nep==0)\"\n",
    "NU_Q += \" & ~(mcf_pass_ccpi0==1)\"\n",
    "NU_Q += \" & ~(mcf_pass_ccnopi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_ncnopi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_cccpi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_nccpi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "\n",
    "for i,name in enumerate(fname_v):\n",
    "    \n",
    "    #if (i == 0):\n",
    "    #    continue # skip LEE event. This one will be done within SBNFit\n",
    "        \n",
    "    df = dfsave_v[i]\n",
    "    \n",
    "    RUNS = \"run3/\"\n",
    "    if (i > 10):\n",
    "        RUNS = \"run2/\"\n",
    "    if (i > 12):\n",
    "        RUNS = \"run1/\"\n",
    "    \n",
    "    fout = open(ls.ntuple_path+RUNS+name+ls.APPEND+'.txt','w')\n",
    "    dfsel = df.query(QUERY)\n",
    "    if ( (i == 2) or (i == 11) or (i==15)):\n",
    "        dfsel = dfsel.query(NU_Q)\n",
    "    print ('file %s has %i selected entries'%(name,dfsel.shape[0]))\n",
    "    for i,row in dfsel.iterrows():\n",
    "        run = row['run']\n",
    "        sub = row['sub']\n",
    "        evt = row['evt']\n",
    "        fout.write('%i %i %i \\n'%(run,sub,evt))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p preselection\n",
    "ZPPRESEL = PRESQ\n",
    "ZPPRESEL += ' and n_tracks_contained == 0'\n",
    "ZPPRESEL += ' and n_showers_contained > 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p box cuts\n",
    "ZPBOXCUTS = ZPPRESEL\n",
    "ZPBOXCUTS += ' and n_showers_contained == 1'\n",
    "ZPBOXCUTS += ' and shrmoliereavg > 1 and shrmoliereavg < 8'\n",
    "ZPBOXCUTS += ' and shr_score < 0.05'\n",
    "ZPBOXCUTS += ' and CosmicIPAll3D > 20. '\n",
    "ZPBOXCUTS += ' and (CosmicDirAll3D<0.75 and CosmicDirAll3D>-0.75)'\n",
    "ZPBOXCUTS += ' and trkfit < 0.4'\n",
    "ZPBOXCUTS += ' and subcluster > 6'\n",
    "ZPBOXCUTS += \" and (shr_tkfit_gap10_dedx_Y>1.5 & shr_tkfit_gap10_dedx_Y<2.5)\"\n",
    "ZPBOXCUTS += \" and (shr_tkfit_gap10_dedx_U>1.5 & shr_tkfit_gap10_dedx_U<3.75)\"\n",
    "ZPBOXCUTS += \" and (shr_tkfit_gap10_dedx_V>1.5 & shr_tkfit_gap10_dedx_V<3.75)\"\n",
    "ZPBOXCUTS += \" and shr_tkfit_2cm_dedx_max>1. and shr_tkfit_2cm_dedx_max<4.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p loose selection -- used to train BDT\n",
    "ZPLOOSESEL = ZPPRESEL\n",
    "ZPLOOSESEL += ' and n_showers_contained == 1'\n",
    "ZPLOOSESEL += ' and CosmicIPAll3D > 10.'\n",
    "ZPLOOSESEL += ' and CosmicDirAll3D > -0.9 and CosmicDirAll3D < 0.9'\n",
    "ZPLOOSESEL += ' and shrmoliereavg < 15'\n",
    "ZPLOOSESEL += ' and subcluster > 4'\n",
    "ZPLOOSESEL += ' and trkfit < 0.65'\n",
    "ZPLOOSESEL += ' and secondshower_Y_nhit < 50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p bdt cut\n",
    "ZPBDT = ZPLOOSESEL\n",
    "ZPBDT += ' and secondshower_Y_nhit < 20'\n",
    "ZPBDT += ' and bkg_score >0.85'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p loose bdt cut\n",
    "ZPBDTLOOSE = ZPLOOSESEL\n",
    "ZPBDTLOOSE += ' and secondshower_Y_nhit < 20'\n",
    "ZPBDTLOOSE += ' and bkg_score >0.72'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e0p selection\n",
    "QUERY = ZPBDT\n",
    "QUERY += ' and bnbdata==0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1560557343774,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "b93hN-pGYJ9T",
    "outputId": "17e7c7ed-3f12-4b03-805c-6698f1617878",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#VARIABLE, BINS, RANGE, XTIT = 'reco_e',14,(0.15,1.55),\"Reconstructed Energy [GeV]\"\n",
    "VARIABLE, BINS, RANGE, XTIT = 'reco_e',14,(0.1,1.5),\"Reconstructed Energy [GeV]\"\n",
    "\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'nonpi0_score',10,(0.6,1.0),\"BDT non-$\\pi^0$ score\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'pi0_score',10,(0.6,1.0),\"BDT non-$\\pi^0$ score\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'bkg_score',4,(0.6,1.0),\"BDT background score\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shrmoliereavg',20,(0,20),r\"shr moliereavg\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_score',10,(0,0.4),\"shr score\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'CosmicIP',25,(0,50),\"cosmic ip\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'CosmicIPAll3D',25,(0,250),\"cosmic ip\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'CosmicDirAll3D',10,(-1,1),\"cosmic ip\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'subcluster',20,(0,20),\"sub cluster\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'trkfit',20,(0,1),r\"track fit\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'secondshower_Y_nhit',25,(0,50),r\"second shower nhit y\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'secondshower_Y_dot',20,(0,1),r\"second shower dot y\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'anglediff_Y',25,(0,500),r\"anglediff\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'secondshower_Y_vtxdist',25,(0,500),r\"second shower dot y\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_dedx_Y',40,(0,10),r\"shr tkfit 2cm_dedx_Y\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_dedx_U',40,(0,10),r\"shr tkfit 2cm_dedx_V\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_dedx_Y',40,(0,10),r\"shr tkfit dedx_V\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_dedx_max',40,(0,10),r\"shr tkfit gap 10_dedx_Y\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_gap10_dedx_Y',40,(0,10),r\"shr tkfit gap 10_dedx_U\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_nhits_tot',10,(0,10),r\"shr tkfit gap 10_dedx nhits\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_gap10_nhits_tot',20,(0,40),r\"shr tkfit gap 10_dedx nhits\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_gap10_dedx_avg',40,(0,10),r\"shr tkfit gap 10_dedx_avg\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_dedx_avg',40,(0,10),r\"shr tkfit gap 10_dedx_avg\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_dedx_avg',40,(0,10),r\"shr tkfit gap 10_dedx_avg\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_gap10_dedx_max',40,(0,10),r\"shr tkfit gap 10_dedx_max\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_2cm_dedx_max',40,(0,10),r\"shr tkfit 2 cm_dedx_max\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_dedx_max',40,(0,10),r\"shr tkfit _dedx_max\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'pi0_mass_Y',20,(0,500),\"pi0 mass Y\"\n",
    "\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shrMCSMom',20,(0,200),\"shrmcs mom\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'shrPCA1CMed_5cm',10,(0.5,1),\"shrmcs mom\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'DeltaRMS2h',20,(0,10),\"shrmcs mom\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'CylFrac2h_1cm',20,(0,1),\"shrmcs mom\"\n",
    "\n",
    "#\"shrMCSMom\",\"DeltaRMS2h\",\"shrPCA1CMed_5cm\",\"CylFrac2h_1cm\"\n",
    "\n",
    "fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=QUERY,\n",
    "    kind=\"event_category\",\n",
    "    #kind=\"interaction\",\n",
    "    #kind=\"sample\",\n",
    "    #kind='particle_pdg',\n",
    "    draw_sys=False,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=BINS,\n",
    "    range=RANGE,\n",
    ")[0:3]\n",
    "\n",
    "print(\"Profile likelihood: %.2f sigma @ 1.01e21 POT\" % my_plotter.significance_likelihood)\n",
    "print(\"s/sqrt(b): %.2f sigma @ 1.01e21 POT\" % my_plotter.significance)\n",
    "\n",
    "ax1.set_ylim(0,ax1.get_ylim()[1]*1.3)\n",
    "\n",
    "#ax1.set_ylim(0,22)\n",
    "#ax1.set_yscale(\"log\")\n",
    "#ax1.set_ylim(0,230)\n",
    "#ax2.set_ylim(0.5,1.5)\n",
    "fig.savefig(ls.plots_path+VARIABLE+\"_BDT_R1R2R3_higheff.pdf\")\n",
    "#fig.savefig(ls.plots_path+VARIABLE+\"_BoxCut_R1R2R3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eff(df,var,query,acceptance,bin_edges,absval=False):\n",
    "    #print acceptance\n",
    "    bin_centers = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "    bins = []\n",
    "    bin_eff = []\n",
    "    bin_err = []\n",
    "    for i in range(len(bin_centers)):\n",
    "        binmin = bin_edges[i]\n",
    "        binmax = bin_edges[i+1]\n",
    "        bincut = '%s > %f and %s < %f'%(var,binmin,var,binmax)\n",
    "        if (absval == True):\n",
    "            bincut = '(%s > %f and %s < %f) or (%s > -%f and %s < -%f)'%(var,binmin,var,binmax,var,binmax,var,binmin)\n",
    "        if (acceptance != ''): bincut += ' and %s'%acceptance\n",
    "        #print bincut\n",
    "        df_tmp =  df.query(bincut) # cut on bin range for desired var.\n",
    "        df_sub = df_tmp.query(query) # apply constrain \n",
    "        if (df_tmp.shape[0] == 0): continue\n",
    "        eff = df_sub.shape[0] / float( df_tmp.shape[0] )\n",
    "        err = np.sqrt( eff*(1-eff)/df_tmp.shape[0] )\n",
    "        bin_eff.append( eff )\n",
    "        bin_err.append( err )\n",
    "        bins.append(bin_centers[i])\n",
    "        #print 'eff = %.02f @ bin = %.02f'%(eff,bin_centers[i])\n",
    "    return np.array(bins),np.array(bin_eff),np.array(bin_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pur(my_plotter,VARIABLE,QUERY,BINS,RANGE):\n",
    "    fig, ax1, ax2, stack, labls, exty = my_plotter.plot_variable(\n",
    "        VARIABLE,   \n",
    "        query=QUERY,\n",
    "        kind=\"event_category\",\n",
    "        draw_sys=False,\n",
    "        stacksort=3,\n",
    "        title=\"my_xaxis\",\n",
    "        bins=BINS,\n",
    "        range=RANGE,\n",
    "    )\n",
    "    nuel = -1\n",
    "    for i, l in enumerate(labls):\n",
    "        if 'nu_e' in l and 'LEE' in l: \n",
    "            nuel = i\n",
    "            break\n",
    "    plt.close(fig)\n",
    "    return (stack[0][nuel]-stack[0][nuel-1])/(stack[0][nuel]+exty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "bin_edges = np.linspace(0.15,1.55,8)\n",
    "print(bin_edges)\n",
    "\n",
    "VAR = 'nu_e' #'_pi0_e'\n",
    "ACCEPTANCE = 'isVtxInFiducial == 1 and truthFiducial == 1 and npi0==0 and npion==0 and nproton==0'\n",
    "\n",
    "lables = ['1e0p Presel','Loose','Box','BDT','Loose BDT']\n",
    "for i,q in enumerate([ZPPRESEL,ZPLOOSESEL,ZPBOXCUTS,ZPBDT,ZPBDTLOOSE]):\n",
    "#lables = ['New Tight Selection','Old Tight Selection']\n",
    "#for i,q in enumerate([NPTCUTQ,OTCUTQ]):\n",
    "    fmt = 'o-'\n",
    "    centers,vals,errs = Eff(nue,VAR,q,ACCEPTANCE,bin_edges)\n",
    "    ax.errorbar(centers,vals,yerr=errs,xerr=(bin_edges[1]-bin_edges[2])/2,fmt=fmt,label=lables[i])\n",
    "ax.set_xlabel('True Neutrino Energy [GeV]')\n",
    "ax.set_ylabel(r'$\\nu_e$ Selection Efficiency')\n",
    "ax.set_xticks(bin_edges)\n",
    "ax.set_ylim(0.,0.75)\n",
    "#ax.set_ylim(0.,0.15)\n",
    "ax.set_xlim(bin_edges[0],bin_edges[-1])\n",
    "plt.legend()\n",
    "#plt.title(\"dr(shr vtx reco, vtx mc sce)<1.0\")\n",
    "plt.grid(True)\n",
    "#plt.yscale('log')\n",
    "plt.show()\n",
    "fig.savefig(ls.plots_path+\"eff_1e0p_cut_bdt_1shr.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "bin_edges = np.linspace(0.15,1.55,8)\n",
    "bin_centers = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "\n",
    "lables = ['1e0p Presel','Loose','Box','BDT','Loose BDT']\n",
    "for i,q in enumerate([ZPPRESEL,ZPLOOSESEL,ZPBOXCUTS,ZPBDT,ZPBDTLOOSE]):\n",
    "    fmt = 'o-'\n",
    "    vals = Pur(my_plotter,'reco_e',q,len(bin_centers),(bin_edges[0],bin_edges[-1]))\n",
    "    ax.errorbar(bin_centers,vals,xerr=(bin_edges[1]-bin_edges[2])/2,fmt=fmt,label=lables[i])\n",
    "ax.set_xlabel('Reconstructed Energy [GeV]')\n",
    "ax.set_ylabel(r'Intrinsic $\\nu_e$ Purity')\n",
    "ax.set_xticks(bin_edges)\n",
    "ax.set_ylim(0.,1.)\n",
    "ax.set_xlim(bin_edges[0],bin_edges[-1])\n",
    "ax.legend()\n",
    "#plt.title(\"dr(shr vtx reco, vtx mc sce)<1.0\")\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "fig.savefig(ls.plots_path+\"pur_1e0p_cut_bdt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PQUERY = QUERY\n",
    "#PQUERY += ' and reco_e > 0.15 and reco_e < 1.55'\n",
    "PQUERY += ' and reco_e > 0.15 and reco_e < 0.75'\n",
    "#PQUERY += ' and shr_tkfit_dedx_Y < 0'\n",
    "plots = []\n",
    "plots.append(['tksh_distance',20,(0,10),\"tksh distance [cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_Y',20,(0,10),\"shr tkfit dE/dx (Y, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_U',20,(0,10),\"shr tkfit dE/dx (U, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_V',20,(0,10),\"shr tkfit dE/dx (V, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_Y',20,(0,10),\"shr tkfit dE/dx (Y, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_U',20,(0,10),\"shr tkfit dE/dx (U, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_V',20,(0,10),\"shr tkfit dE/dx (V, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_Y',20,(0,10),\"shr tkfit dE/dx (Y, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_U',20,(0,10),\"shr tkfit dE/dx (U, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_V',20,(0,10),\"shr tkfit dE/dx (V, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_avg',20,(0,10),\"shr tkfit dE/dx (avg, 0-4 cm) [MeV/cm]\"])\n",
    "plots.append(['shr_tkfit_dedx_max',20,(0,10),\"shr tkfit dE/dx (max, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_nhits_tot',20,(0,20),\"shr tkfit nhits (tot, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_avg',20,(0,10),\"shr tkfit dE/dx (avg, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_nhits_tot',20,(0,20),\"shr tkfit nhits (tot, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_avg',20,(0,10),\"shr tkfit dE/dx (avg, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_nhits_tot',20,(0,20),\"shr tkfit nhits (tot, 1-5 cm) [MeV/cm]\"])\n",
    "plots.append(['tksh_angle',20,(-1,1),\"cos(tksh angle)\"])\n",
    "plots.append(['trkfit',20,(0,1),\"Fraction of Track-fitted points\"])\n",
    "plots.append(['shrmoliereavg',20,(0,50),\"average Moliere angle [degrees]\"])\n",
    "plots.append(['trkpid',15,(-1,1),\"track LLR PID\"])\n",
    "#plots.append(['n_showers_contained',10,(0,10),\"n showers contained\"])\n",
    "#plots.append(['n_tracks_contained',10,(0,10),\"n tracks contained\"])\n",
    "plots.append(['shr_score',20,(0,0.5),\"shr score\"])\n",
    "#plots.append(['trk_score',20,(0.5,1.0),\"trk score\"])\n",
    "plots.append(['hits_ratio',20,(0,1),\"shower hits/all hits\"])\n",
    "plots.append(['slclustfrac',20,(0,1),\"slice clustered fraction\"])\n",
    "plots.append(['CosmicIP',20,(0,200),\"Cosmic IP from vtx [cm]\"])\n",
    "#plots.append(['reco_nu_vtx_x',20,(0,260),\"x\"])\n",
    "#plots.append(['reco_nu_vtx_y',20,(-120,120),\"y\"])\n",
    "#plots.append(['reco_nu_vtx_z',20,(0,1100),\"z\"])\n",
    "#plots.append(['reco_e_rqe',20,(0,2),\"rqe\"])\n",
    "plots.append(['trkshrhitdist2',20,(0,10),\"2D trk-shr distance (Y)\"])\n",
    "plots.append(['subcluster',20,(0,20),\"N sub-clusters in shower\"])\n",
    "#plots.append(['shrmoliererms',20,(0,5000),\"RMS Moliere angle [degrees]\"])\n",
    "#plots.append(['shr_energy_tot_cali',20,(0,1),\"shr energy (calibrated) [GeV]\"])\n",
    "#plots.append(['contained_fraction',20,(0.,1),\"contained fraction\"])\n",
    "#plots.append(['hits_y',20,(0.,1000),\"N hits Y plane\"])\n",
    "#plots.append(['pi0_mass_Y',25,(-50.,200),\"pi0 mass [Mev]\"])\n",
    "#plots.append(['pi0_gammadot',20,(-1,1),\"2-shower angle\"])\n",
    "plots.append(['secondshower_Y_nhit',20,(0,200),\"Nhit 2nd shower (Y)\"])\n",
    "plots.append(['secondshower_Y_dot',20,(-1,1),\"cos(2nd shower direction wrt vtx) (Y)\"])\n",
    "plots.append(['anglediff_Y',20,(0,350),\"angle diff 1st-2nd shower (Y) [degrees]\"])\n",
    "plots.append(['secondshower_Y_vtxdist',20,(0.,200),\"vtx dist 2nd shower (Y)\"])\n",
    "#plots.append(['trackcaloenergy',15,(0,300),\"Track Calo Energy [Mev]\"])\n",
    "plots.append(['CosmicIPAll3D',20,(0,200),\"CosmicIPAll3D [cm]\"])\n",
    "plots.append(['CosmicDirAll3D',20,(-1,1),\"cos(CosmicDirAll3D)\"])\n",
    "if USEBDT:\n",
    "    plots = []\n",
    "    plots.append(['bkg_score',50,(0.5,1),\"all-bkg BDT response\"])\n",
    "    plots.append(['pi0_score',50,(0.5,1),\"$\\pi^0$ BDT response\"])\n",
    "    plots.append(['nonpi0_score',50,(0.5,1),\"non-$\\pi^0$ BDT response\"])\n",
    "    #plots.append(['cc_score',40,(0.,1),\"cc score\"])\n",
    "    #plots.append(['cosmic_score',40,(0.,1),\"cosmic score\"])\n",
    "    #plots.append(['ext_score',40,(0.,1),\"ext score\"])\n",
    "    #plots.append(['ccpi0_score',40,(0.,1),\"ccpi0 score\"])\n",
    "    #plots.append(['ncpi0_score',40,(0.,1),\"ncpi0 score\"])\n",
    "#plots = []\n",
    "#plots.append(['secondshower_Y_nhit',20,(0,100),\"Nhit 2nd shower (Y)\"])\n",
    "for VARIABLE, BINS, RANGE, XTIT in plots:\n",
    "    print(VARIABLE, BINS, RANGE, XTIT)\n",
    "    fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "        VARIABLE,   \n",
    "        query=PQUERY,\n",
    "        kind=\"event_category\",\n",
    "        #kind=\"interaction\",\n",
    "        #kind=\"sample\",\n",
    "        draw_sys=False,\n",
    "        stacksort=3,\n",
    "        title=XTIT,\n",
    "        bins=BINS,\n",
    "        range=RANGE,\n",
    "    )[0:3]\n",
    "    ax1.set_ylim(0,ax1.get_ylim()[1]*1.4)\n",
    "    #ax1.set_yscale(\"log\")\n",
    "    fig.show()\n",
    "    #fig.savefig(ls.plots_path+\"0109/run1/presel/\"+VARIABLE+date_time+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY += ' and reco_e > 0.2 and reco_e < 0.8 and npi0==0 and ccnc==1'# and npion>0\n",
    "QUERY += \" and nu_pdg == 14\"\n",
    "#QUERY += \" and ~(pi0truth_elec_etot>=15 or muon_e<0.3)\"\n",
    "print(QUERY)\n",
    "mc.query(QUERY)[[\"run\",\"sub\",\"evt\",\"reco_e\",\"slnunhits\",\"slnhits\",\"ccnc\",\"nu_e\",\"npi0\",\"npion\",\"nproton\",\"proton_e\",\"nneutron\",\"muon_e\",\"pi0truth_elec_etot\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output files based on selection\n",
    "fname_v = [NUE,NU,PI0,NUE,EXT,BNB,DRT]\n",
    "\n",
    "for i,name in enumerate(fname_v):\n",
    "    if (i == 0):\n",
    "        continue # skip LEE event. This one will be done within SBNFit\n",
    "        \n",
    "    df = dfbdt_v[i]\n",
    "\n",
    "    fout = open(ls.ntuple_path+name+'.txt','w')\n",
    "    dfsel = df.query(QUERY)\n",
    "    print ('file %s has %i selected entries'%(name,dfsel.shape[0]))\n",
    "    for i,row in dfsel.iterrows():\n",
    "        run = row['run'].values[0]\n",
    "        sub = row['sub'].values[0]\n",
    "        evt = row['evt'].values[0]\n",
    "        fout.write('%i %i %i \\n'%(run,sub,evt))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BINS = np.linspace(0,1,25)\n",
    "VAR = 'cosmic_score'\n",
    "\n",
    "nueplot = nue.query(QUERY)\n",
    "nueplotecut = nueplot.query('nu_e < 0.8')\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.hist(nueplot[VAR].values,bins=BINS,histtype='step',lw=2,color='red',label='all nue')\n",
    "plt.hist(nueplotecut[VAR].values,bins=BINS,histtype='step',lw=2,color='m',label='nue < 0.8 GeV')\n",
    "#plt.hist(nue[VAR].values,bins=BINS,histtype='step',lw=2,color='green')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(VAR)\n",
    "plt.show()\n",
    "\n",
    "BINS2D = (np.linspace(0,3.0,25),BINS)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.hist2d(nueplot['nu_e'].values,nueplot[VAR].values,bins=BINS2D)\n",
    "#plt.hist(nue[VAR].values,bins=BINS,histtype='step',lw=2,color='green')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_range = (0.1,0.8)\n",
    "n_bins = 7\n",
    "\n",
    "n_tot = np.empty([50, n_bins])\n",
    "n_cv_tot = np.empty(n_bins)\n",
    "n_tot.fill(0)\n",
    "n_cv_tot.fill(0)\n",
    "score_cut = 0.997\n",
    "\n",
    "my_cmap = cm.get_cmap('viridis')\n",
    "\n",
    "for t in samples:\n",
    "    if t in [\"ext\", \"data\", \"lee\"]:\n",
    "        continue\n",
    "    tree = samples[t]\n",
    "    \n",
    "    extra_query = \"\"\n",
    "    if t == \"mc\":\n",
    "        extra_query = \"& ~(nu_pdg == 12 & ccnc == 0) & ~(npi0 != 0 & ccnc == 1)\"\n",
    "        \n",
    "    queried_tree = tree.query(\"selected==1 & global_score > %g %s & interaction == 1\" % (score_cut, extra_query))\n",
    "    variable = queried_tree[\"reco_e\"]\n",
    "    genie_weights = queried_tree[\"weightsGenie\"]\n",
    "    spline_fix = queried_tree[\"weightSpline\"]*weights[t]\n",
    "\n",
    "    s = genie_weights\n",
    "    df = pd.DataFrame(s.values.tolist())\n",
    "\n",
    "\n",
    "    n_cv, bins = np.histogram(\n",
    "        variable,\n",
    "        range=x_range,\n",
    "        bins=n_bins,\n",
    "        weights=spline_fix)\n",
    "    \n",
    "    n_cv_tot += n_cv\n",
    "\n",
    "    if not df.empty:\n",
    "        for i in range(50):\n",
    "            weight = df[i].values\n",
    "            weight[np.isnan(weight)] = 1\n",
    "            weight[weight > 100] = 1\n",
    "\n",
    "            n, bins = np.histogram(\n",
    "                variable, weights=weight*spline_fix, range=x_range, bins=n_bins)\n",
    "\n",
    "            n_tot[i] += n\n",
    "\n",
    "        \n",
    "bincenters = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "left,right = bins[:-1],bins[1:]\n",
    "X = np.array([left,right]).T.flatten()\n",
    "Y = np.array([n_cv_tot,n_cv_tot]).T.flatten()\n",
    "plt.plot(X,Y,color='r',linewidth=2,label='Central value')\n",
    "\n",
    "    \n",
    "cov = np.empty([len(n_cv), len(n_cv)])\n",
    "cov.fill(0)\n",
    "\n",
    "my_norm = Normalize(vmin=min((sum(n) for n in n_tot)), vmax=max((sum(n) for n in n_tot)))\n",
    "\n",
    "for n in n_tot:\n",
    "    left,right = bins[:-1],bins[1:]\n",
    "    X = np.array([left,right]).T.flatten()\n",
    "    Y = np.array([n,n]).T.flatten()\n",
    "    plt.plot(X,Y,color=my_cmap(my_norm(sum(n))),zorder=-32)\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            cov[i][j] += (n[i] - n_cv_tot[i]) * (n[j] - n_cv_tot[j])\n",
    "\n",
    "cov /= 50\n",
    "            \n",
    "frac_cov = np.empty([len(n_cv), len(n_cv)])\n",
    "corr = np.empty([len(n_cv), len(n_cv)])\n",
    "\n",
    "for i in range(len(n_cv)):\n",
    "    for j in range(len(n_cv)):\n",
    "        frac_cov[i][j] = cov[i][j] / (n_cv_tot[i] * n_cv_tot[j])\n",
    "        corr[i][j] = cov[i][j] / np.sqrt(cov[i][i] * cov[j][j])\n",
    "\n",
    "        \n",
    "plt.errorbar(\n",
    "    bincenters, \n",
    "    n_cv_tot,\n",
    "    yerr=np.sqrt(np.diag(cov)), \n",
    "    fmt='none', \n",
    "    ecolor='r',\n",
    "    linewidth=2,\n",
    "    label='GENIE sys. uncertainties')\n",
    "\n",
    "print(np.sqrt(np.diag(cov))/n_cv_tot)\n",
    "plt.xlim(x_range[0], x_range[1])\n",
    "plt.xlabel(r\"$E_{deposited}$ [GeV]\")\n",
    "plt.legend()\n",
    "plt.ylim(ymin=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/spec.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "pos = ax.imshow(frac_cov, origin='lower', cmap='viridis')\n",
    "ax.set_title(\"Fractional covariance matrix\")\n",
    "ax.set_ylabel(\"Bin number\")\n",
    "ax.set_xlabel(\"Bin number\")\n",
    "fig.colorbar(pos)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/frac.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title(\"Correlation matrix\")\n",
    "pos = ax.imshow(corr, origin='lower', cmap='inferno')\n",
    "ax.set_ylabel(\"Bin number\")\n",
    "ax.set_xlabel(\"Bin number\")\n",
    "fig.colorbar(pos)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/corr.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_plotter.plot_2d(\n",
    "    \"global_score\",\n",
    "    \"ncpi0_score\",\n",
    "    query=\"selected==1\",\n",
    "    bins_x=50,\n",
    "    bins_y=50,\n",
    "    range_x=(0., 1),\n",
    "    range_y=(0., 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
