{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unblinding far sideband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING BDT?\n",
    "USEBDT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cale to MCC8 CV?\n",
    "MCC8WEIGHTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = ls.fold\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "R3BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_G1_beam_good_reco2_1e19'\n",
    "R3EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G_all_reco2'\n",
    "R3NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "R3NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3NCPI0  = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "R3CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "R3CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run3_reco2_reco2'\n",
    "R3CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "R3NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "R3NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "\n",
    "ur3mc = uproot.open(ls.ntuple_path+ls.RUN3+R3NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nue = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3data = uproot.open(ls.ntuple_path+ls.RUN3+R3BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ext = uproot.open(ls.ntuple_path+ls.RUN3+R3EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3dirt = uproot.open(ls.ntuple_path+ls.RUN3+R3DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3lee = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3cccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R2NU = \"prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run2_reco2_D1D2_reco2\"\n",
    "R2NUE = \"prodgenie_bnb_intrinsic_nue_overlay_run2_v08_00_00_35_run2a_reco2_reco2\"\n",
    "\n",
    "ur2mc = uproot.open(ls.ntuple_path+ls.RUN2+R2NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2nue = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2lee = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R1BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_beam_good_reco2_5e19'\n",
    "#R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_all_reco2'\n",
    "R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_C2_D1_D2_E1_E2_all_reco2' #Run1 + Run2\n",
    "R1NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "R1NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1NCPI0  = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "R1CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "R1CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run1_reco2_reco2'\n",
    "R1CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    \n",
    "ur1mc = uproot.open(ls.ntuple_path+ls.RUN1+R1NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nue = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1data = uproot.open(ls.ntuple_path+ls.RUN1+R1BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ext = uproot.open(ls.ntuple_path+ls.RUN1+R1EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1dirt = uproot.open(ls.ntuple_path+ls.RUN1+R1DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1lee = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1cccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R123_FAR_SIDEBAND_BNB = '1enp_far_sidebands'\n",
    "ur123data_far_sidebands = uproot.open(ls.ntuple_path+'data_sidebands/'+R123_FAR_SIDEBAND_BNB+\".root\")['nuselection'][tree]\n",
    "\n",
    "variables = [\n",
    "    \"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\",\n",
    "    \"shr_tkfit_dedx_U\",\"shr_tkfit_dedx_V\",\"shr_tkfit_dedx_Y\",\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "    #\"shr_energy_tot\", \n",
    "    \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    \"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    #\"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\"CosmicDirAll3D\",\"CosmicIPAll3D\",\n",
    "    \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "    #\"trk_pfp_id\",\n",
    "    \"shrmoliereavg\",\"shrmoliererms\",\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "    \"trkshrhitdist2\", \"trkshrhitdist0\",\"trkshrhitdist1\", #distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    #\"pi0_energy2_Y\", # pi0 tagger variables\n",
    "    \"_opfilter_pe_beam\", \"_opfilter_pe_veto\", # did the event pass the common optical filter (for MC only)\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "    \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"shr_tkfit_nhits_Y\",\"shr_tkfit_nhits_U\",\"shr_tkfit_nhits_V\",\n",
    "    \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_U\",\"shr_tkfit_2cm_nhits_V\",\n",
    "    \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_U\",\"shr_tkfit_gap10_nhits_V\"\n",
    "]\n",
    "#make the list unique\n",
    "variables = list(set(variables))\n",
    "print(variables)\n",
    "\n",
    "variables.remove(\"_closestNuCosmicDist\")\n",
    "variables.remove(\"crtveto\")\n",
    "variables.remove(\"crthitpe\")\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "\n",
    "r3nue = ur3nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3mc = ur3mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r3ncpi0 = ur3ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccpi0 = ur3ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccnopi = ur3ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3cccpi = ur3cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ncnopi = ur3ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3nccpi = ur3nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3data = ur3data.pandas.df(variables, flatten=False)\n",
    "r3ext = ur3ext.pandas.df(variables, flatten=False)\n",
    "r3dirt = ur3dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3lee = ur3lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r3lee[\"is_signal\"] = r3lee[\"category\"] == 11\n",
    "r3data[\"is_signal\"] = r3data[\"category\"] == 11\n",
    "r3nue[\"is_signal\"] = r3nue[\"category\"] == 11\n",
    "r3mc[\"is_signal\"] = r3mc[\"category\"] == 11\n",
    "r3dirt[\"is_signal\"] = r3dirt[\"category\"] == 11\n",
    "r3ext[\"is_signal\"] = r3ext[\"category\"] == 11\n",
    "r3ncpi0[\"is_signal\"] = r3ncpi0[\"category\"] == 11\n",
    "r3ccpi0[\"is_signal\"] = r3ccpi0[\"category\"] == 11\n",
    "r3ccnopi[\"is_signal\"] = r3ccnopi[\"category\"] == 11\n",
    "r3cccpi[\"is_signal\"] = r3cccpi[\"category\"] == 11\n",
    "r3ncnopi[\"is_signal\"] = r3ncnopi[\"category\"] == 11\n",
    "r3nccpi[\"is_signal\"] = r3nccpi[\"category\"] == 11\n",
    "r3lee.loc[r3lee['category'] == 1, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 10, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur3lee,ur3mc,ur3ncpi0,ur3ccpi0,ur3ccnopi,ur3cccpi,ur3ncnopi,ur3nccpi,ur3nue,ur3ext,ur3data,ur3dirt]\n",
    "df_v = [r3lee,r3mc,r3ncpi0,r3ccpi0,r3ccnopi,r3cccpi,r3ncnopi,r3nccpi,r3nue,r3ext,r3data,r3dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_energy_proton_v = up.array('trk_energy_proton_v')\n",
    "    #shr_moliere_avg_v = up.array('shr_moliere_avg_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    #shr_id = up.array('shr_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    #shr_moliere_avg_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(shr_moliere_avg_v,shr_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    df['protonenergy'] = trk_energy_proton_sel\n",
    "    #df['shrmoliereavg'] = shr_moliere_avg_sel\n",
    "    \n",
    "if (USEBDT == True):\n",
    "    train_r3ccpi0, r3ccpi0 = train_test_split(r3ccpi0, test_size=0.5, random_state=1990)\n",
    "    \n",
    "r1nue = ur1nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1mc = ur1mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r1ncpi0 = ur1ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccpi0 = ur1ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccnopi = ur1ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1cccpi = ur1cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ncnopi = ur1ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1nccpi = ur1nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1data = ur1data.pandas.df(variables, flatten=False)\n",
    "r1ext = ur1ext.pandas.df(variables, flatten=False)\n",
    "r1dirt = ur1dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1lee = ur1lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "\n",
    "r123data_far_sidebands = ur123data_far_sidebands.pandas.df(variables, flatten=False)\n",
    "\n",
    "r1lee[\"is_signal\"] = r1lee[\"category\"] == 11\n",
    "r1data[\"is_signal\"] = r1data[\"category\"] == 11\n",
    "r1nue[\"is_signal\"] = r1nue[\"category\"] == 11\n",
    "r1mc[\"is_signal\"] = r1mc[\"category\"] == 11\n",
    "r1dirt[\"is_signal\"] = r1dirt[\"category\"] == 11\n",
    "r1ext[\"is_signal\"] = r1ext[\"category\"] == 11\n",
    "r1ncpi0[\"is_signal\"] = r1ncpi0[\"category\"] == 11\n",
    "r1ccpi0[\"is_signal\"] = r1ccpi0[\"category\"] == 11\n",
    "r1ccnopi[\"is_signal\"] = r1ccnopi[\"category\"] == 11\n",
    "r1cccpi[\"is_signal\"] = r1cccpi[\"category\"] == 11\n",
    "r1ncnopi[\"is_signal\"] = r1ncnopi[\"category\"] == 11\n",
    "r1nccpi[\"is_signal\"] = r1nccpi[\"category\"] == 11\n",
    "r1lee.loc[r1lee['category'] == 1, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 10, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "r123data_far_sidebands[\"is_signal\"] = r123data_far_sidebands[\"category\"] == 11\n",
    "\n",
    "uproot_v = [ur1lee,ur1mc,ur1ncpi0,ur1ccpi0,ur1ccnopi,ur1cccpi,ur1ncnopi,ur1nccpi,ur1nue,ur1ext,ur1data,ur1dirt, ur123data_far_sidebands]\n",
    "df_v = [r1lee,r1mc,r1ncpi0,r1ccpi0,r1ccnopi,r1cccpi,r1ncnopi,r1nccpi,r1nue,r1ext,r1data,r1dirt, r123data_far_sidebands]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_energy_proton_v = up.array('trk_energy_proton_v')\n",
    "    #shr_moliere_avg_v = up.array('shr_moliere_avg_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    #shr_id = up.array('shr_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    #shr_moliere_avg_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(shr_moliere_avg_v,shr_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    df['protonenergy'] = trk_energy_proton_sel\n",
    "    #df['shrmoliereavg'] = shr_moliere_avg_sel\n",
    "\n",
    "\n",
    "r2nue = ur2nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r2mc = ur2mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r2lee = ur2lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r2lee[\"is_signal\"] = r2lee[\"category\"] == 11\n",
    "r2nue[\"is_signal\"] = r2nue[\"category\"] == 11\n",
    "r2mc[\"is_signal\"] = r2mc[\"category\"] == 11\n",
    "r2lee.loc[r2lee['category'] == 1, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 10, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur2lee,ur2mc,ur2nue]\n",
    "df_v = [r2lee,r2mc,r2nue]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_energy_proton_v = up.array('trk_energy_proton_v')\n",
    "    #shr_moliere_avg_v = up.array('shr_moliere_avg_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    #shr_id = up.array('shr_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    #shr_moliere_avg_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(shr_moliere_avg_v,shr_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    df['protonenergy'] = trk_energy_proton_sel\n",
    "    #df['shrmoliereavg'] = shr_moliere_avg_sel\n",
    "\n",
    "nue = pd.concat([r1nue,r2nue,r3nue],ignore_index=True)\n",
    "#nue = pd.concat([r3nue,r1nue],ignore_index=True)\n",
    "mc = pd.concat([r3mc,r2mc,r1mc],ignore_index=True)\n",
    "#mc = pd.concat([r3mc,r1mc],ignore_index=True)\n",
    "ncpi0 = pd.concat([r3ncpi0,r1ncpi0],ignore_index=True)\n",
    "ccpi0 = pd.concat([r3ccpi0,r1ccpi0],ignore_index=True)\n",
    "ccnopi = pd.concat([r3ccnopi,r1ccnopi],ignore_index=True)\n",
    "cccpi = pd.concat([r3cccpi,r1cccpi],ignore_index=True)\n",
    "ncnopi = pd.concat([r3ncnopi,r1ncnopi],ignore_index=True)\n",
    "nccpi = pd.concat([r3nccpi,r1nccpi],ignore_index=True)\n",
    "# data = pd.concat([r3data,r1data],ignore_index=True)\n",
    "data = pd.concat([r123data_far_sidebands],ignore_index=True)\n",
    "ext = pd.concat([r3ext,r1ext],ignore_index=True)\n",
    "dirt = pd.concat([r3dirt,r1dirt],ignore_index=True)\n",
    "lee = pd.concat([r1lee,r2lee,r3lee],ignore_index=True)\n",
    "#lee = pd.concat([r3lee,r1lee],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "''' version for DAVID C\n",
    "fold = ls.fold\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "PATHDATA = '/home/david/data/searchingfornues/v08_00_00_42/cc0pinp/0420/'\n",
    "\n",
    "R3BNB = 'neutrinoselection_filt_1enp_far_sideband_skimmed_Run3'\n",
    "R3EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G_all_reco2'\n",
    "R3NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "R3NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3NCPI0  = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "R3CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "R3CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run3_reco2_reco2'\n",
    "R3CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "R3NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "R3NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "\n",
    "ur3mc = uproot.open(ls.ntuple_path+ls.RUN3+R3NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nue = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3data = uproot.open(PATHDATA+R3BNB+\".root\")['nuselection'][tree]\n",
    "ur3ext = uproot.open(ls.ntuple_path+ls.RUN3+R3EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3dirt = uproot.open(ls.ntuple_path+ls.RUN3+R3DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3lee = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3cccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R2BNB = \"neutrinoselection_filt_1enp_far_sideband_skimmed_Run2\"\n",
    "R2NU = \"prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run2_reco2_D1D2_reco2\"\n",
    "R2NUE = \"prodgenie_bnb_intrinsic_nue_overlay_run2_v08_00_00_35_run2a_reco2_reco2\"\n",
    "\n",
    "ur2data = uproot.open(PATHDATA+R2BNB+\".root\")['nuselection'][tree]\n",
    "ur2mc = uproot.open(ls.ntuple_path+ls.RUN2+R2NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2nue = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2lee = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R1BNB = 'neutrinoselection_filt_1enp_far_sideband_skimmed_C1'\n",
    "#R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_all_reco2'\n",
    "R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_C2_D1_D2_E1_E2_all_reco2' #Run1 + Run2\n",
    "R1NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "R1NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1NCPI0  = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "R1CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "R1CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run1_reco2_reco2'\n",
    "R1CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    \n",
    "ur1mc = uproot.open(ls.ntuple_path+ls.RUN1+R1NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nue = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1data = uproot.open(PATHDATA+R1BNB+\".root\")['nuselection'][tree]\n",
    "ur1ext = uproot.open(ls.ntuple_path+ls.RUN1+R1EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1dirt = uproot.open(ls.ntuple_path+ls.RUN1+R1DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1lee = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1cccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "variables = [\n",
    "    \"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\",\n",
    "    \"shr_tkfit_dedx_U\",\"shr_tkfit_dedx_V\",\"shr_tkfit_dedx_Y\",\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "    #\"shr_energy_tot\", \n",
    "    \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    \"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy2\",\n",
    "    #\"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\"CosmicDirAll3D\",\"CosmicIPAll3D\",\n",
    "    \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "    #\"trk_pfp_id\",\n",
    "    \"shrmoliereavg\",\"shrmoliererms\",\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "    \"trkshrhitdist2\", # \"trkshrhitdist0\",\"trkshrhitdist1\", distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    #\"pi0_energy2_Y\", # pi0 tagger variables\n",
    "    \"_opfilter_pe_beam\", \"_opfilter_pe_veto\", # did the event pass the common optical filter (for MC only)\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "    \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"shr_tkfit_nhits_Y\",\"shr_tkfit_nhits_U\",\"shr_tkfit_nhits_V\",\n",
    "    \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_U\",\"shr_tkfit_2cm_nhits_V\",\n",
    "    \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_U\",\"shr_tkfit_gap10_nhits_V\"\n",
    "]\n",
    "#make the list unique\n",
    "variables = list(set(variables))\n",
    "print(variables)\n",
    "\n",
    "variables.remove(\"_closestNuCosmicDist\")\n",
    "variables.remove(\"crtveto\")\n",
    "variables.remove(\"crthitpe\")\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "\n",
    "r3nue = ur3nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3mc = ur3mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r3ncpi0 = ur3ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccpi0 = ur3ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccnopi = ur3ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3cccpi = ur3cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ncnopi = ur3ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3nccpi = ur3nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3data = ur3data.pandas.df(variables, flatten=False)\n",
    "r3ext = ur3ext.pandas.df(variables, flatten=False)\n",
    "r3dirt = ur3dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3lee = ur3lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r3lee[\"is_signal\"] = r3lee[\"category\"] == 11\n",
    "r3data[\"is_signal\"] = r3data[\"category\"] == 11\n",
    "r3nue[\"is_signal\"] = r3nue[\"category\"] == 11\n",
    "r3mc[\"is_signal\"] = r3mc[\"category\"] == 11\n",
    "r3dirt[\"is_signal\"] = r3dirt[\"category\"] == 11\n",
    "r3ext[\"is_signal\"] = r3ext[\"category\"] == 11\n",
    "r3ncpi0[\"is_signal\"] = r3ncpi0[\"category\"] == 11\n",
    "r3ccpi0[\"is_signal\"] = r3ccpi0[\"category\"] == 11\n",
    "r3ccnopi[\"is_signal\"] = r3ccnopi[\"category\"] == 11\n",
    "r3cccpi[\"is_signal\"] = r3cccpi[\"category\"] == 11\n",
    "r3ncnopi[\"is_signal\"] = r3ncnopi[\"category\"] == 11\n",
    "r3nccpi[\"is_signal\"] = r3nccpi[\"category\"] == 11\n",
    "r3lee.loc[r3lee['category'] == 1, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 10, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur3lee,ur3mc,ur3ncpi0,ur3ccpi0,ur3ccnopi,ur3cccpi,ur3ncnopi,ur3nccpi,ur3nue,ur3ext,ur3data,ur3dirt]\n",
    "df_v = [r3lee,r3mc,r3ncpi0,r3ccpi0,r3ccnopi,r3cccpi,r3ncnopi,r3nccpi,r3nue,r3ext,r3data,r3dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "\n",
    "if (USEBDT == True):\n",
    "    train_r3ccpi0, r3ccpi0 = train_test_split(r3ccpi0, test_size=0.5, random_state=1990)\n",
    "    \n",
    "r1nue = ur1nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1mc = ur1mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r1ncpi0 = ur1ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccpi0 = ur1ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccnopi = ur1ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1cccpi = ur1cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ncnopi = ur1ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1nccpi = ur1nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1data = ur1data.pandas.df(variables, flatten=False)\n",
    "r1ext = ur1ext.pandas.df(variables, flatten=False)\n",
    "r1dirt = ur1dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1lee = ur1lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r1lee[\"is_signal\"] = r1lee[\"category\"] == 11\n",
    "r1data[\"is_signal\"] = r1data[\"category\"] == 11\n",
    "r1nue[\"is_signal\"] = r1nue[\"category\"] == 11\n",
    "r1mc[\"is_signal\"] = r1mc[\"category\"] == 11\n",
    "r1dirt[\"is_signal\"] = r1dirt[\"category\"] == 11\n",
    "r1ext[\"is_signal\"] = r1ext[\"category\"] == 11\n",
    "r1ncpi0[\"is_signal\"] = r1ncpi0[\"category\"] == 11\n",
    "r1ccpi0[\"is_signal\"] = r1ccpi0[\"category\"] == 11\n",
    "r1ccnopi[\"is_signal\"] = r1ccnopi[\"category\"] == 11\n",
    "r1cccpi[\"is_signal\"] = r1cccpi[\"category\"] == 11\n",
    "r1ncnopi[\"is_signal\"] = r1ncnopi[\"category\"] == 11\n",
    "r1nccpi[\"is_signal\"] = r1nccpi[\"category\"] == 11\n",
    "r1lee.loc[r1lee['category'] == 1, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 10, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur1lee,ur1mc,ur1ncpi0,ur1ccpi0,ur1ccnopi,ur1cccpi,ur1ncnopi,ur1nccpi,ur1nue,ur1ext,ur1data,ur1dirt]\n",
    "df_v = [r1lee,r1mc,r1ncpi0,r1ccpi0,r1ccnopi,r1cccpi,r1ncnopi,r1nccpi,r1nue,r1ext,r1data,r1dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "\n",
    "\n",
    "r2data = ur2data.pandas.df(variables, flatten=False)\n",
    "r2nue = ur2nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r2mc = ur2mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r2lee = ur2lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r2lee[\"is_signal\"] = r2lee[\"category\"] == 11\n",
    "r2nue[\"is_signal\"] = r2nue[\"category\"] == 11\n",
    "r2mc[\"is_signal\"] = r2mc[\"category\"] == 11\n",
    "r2lee.loc[r2lee['category'] == 1, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 10, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur2data,ur2lee,ur2mc,ur2nue]\n",
    "df_v = [r2data,r2lee,r2mc,r2nue]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    \n",
    "    \n",
    "    \n",
    "nue = pd.concat([r1nue,r2nue,r3nue],ignore_index=True)\n",
    "#nue = pd.concat([r3nue,r1nue],ignore_index=True)\n",
    "mc = pd.concat([r3mc,r2mc,r1mc],ignore_index=True)\n",
    "#mc = pd.concat([r3mc,r1mc],ignore_index=True)\n",
    "ncpi0 = pd.concat([r3ncpi0,r1ncpi0],ignore_index=True)\n",
    "ccpi0 = pd.concat([r3ccpi0,r1ccpi0],ignore_index=True)\n",
    "ccnopi = pd.concat([r3ccnopi,r1ccnopi],ignore_index=True)\n",
    "cccpi = pd.concat([r3cccpi,r1cccpi],ignore_index=True)\n",
    "ncnopi = pd.concat([r3ncnopi,r1ncnopi],ignore_index=True)\n",
    "nccpi = pd.concat([r3nccpi,r1nccpi],ignore_index=True)\n",
    "data = pd.concat([r3data,r2data,r1data],ignore_index=True)\n",
    "ext = pd.concat([r3ext,r1ext],ignore_index=True)\n",
    "dirt = pd.concat([r3dirt,r1dirt],ignore_index=True)\n",
    "lee = pd.concat([r1lee,r2lee,r3lee],ignore_index=True)\n",
    "#lee = pd.concat([r3lee,r1lee],ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    #df.loc[ df['npi0'] > 0, 'weightSplineTimesTune' ] = df['weightSpline'] * df['weightTune'] * 0.759\n",
    "    #df['weightSpline']  = df['weightSpline']  * df['weightTune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust from MCC9 CV to MCC8 CV\n",
    "\n",
    "if (MCC8WEIGHTS == True):\n",
    "\n",
    "    # scaling for QE\n",
    "    CV_bins = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,5.0]\n",
    "    CV_scaling = [2.5,2.0,1.7,1.45,1.3,1.25,1.175,1.15,1.14,1.1]\n",
    "    # scaling for RES\n",
    "\n",
    "    mc.loc[ (mc['interaction'] == 10), 'weightSpline' ] = 2 * mc['weightSpline']\n",
    "    ncpi0.loc[ (ncpi0['interaction'] == 10), 'weightSpline' ] = 2 * ncpi0['weightSpline']\n",
    "    ccpi0.loc[ (ccpi0['interaction'] == 10), 'weightSpline' ] = 2 * ccpi0['weightSpline']\n",
    "    ccnopi.loc[ (ccnopi['interaction'] == 10), 'weightSpline' ] = 2 * ccnopi['weightSpline']\n",
    "    cccpi.loc[ (cccpi['interaction'] == 10), 'weightSpline' ] = 2 * cccpi['weightSpline']\n",
    "    ncnopi.loc[ (ncnopi['interaction'] == 10), 'weightSpline' ] = 2 * ncnopi['weightSpline']\n",
    "    nccpi.loc[ (nccpi['interaction'] == 10), 'weightSpline' ] = 2 * nccpi['weightSpline']\n",
    "    nue.loc[ (nue['interaction'] == 10), 'weightSpline' ] = 2 * nue['weightSpline']\n",
    "    lee.loc[ (lee['interaction'] == 10), 'weightSpline' ] = 2 * lee['weightSpline']\n",
    "    dirt.loc[ (dirt['interaction'] == 10), 'weightSpline' ] = 2 * dirt['weightSpline']\n",
    "\n",
    "    for i, CV_bin in enumerate(CV_bins):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        mc.loc[ (mc['nu_e'] > CV_bins[i-1]) & (mc['nu_e'] < CV_bins[i]) & (mc['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * mc['weightSpline']\n",
    "        nue.loc[ (nue['nu_e'] > CV_bins[i-1]) & (nue['nu_e'] < CV_bins[i]) & (nue['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nue['weightSpline']\n",
    "        ncpi0.loc[ (nc['nu_e'] > CV_bins[i-1]) & (ncpi0['nu_e'] < CV_bins[i]) & (ncpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncpi0['weightSpline']\n",
    "        ccpi0.loc[ (ccpi0['nu_e'] > CV_bins[i-1]) & (ccpi0['nu_e'] < CV_bins[i]) & (ccpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccpi0['weightSpline']\n",
    "        ccnopi.loc[ (ccnopi['nu_e'] > CV_bins[i-1]) & (ccnopi['nu_e'] < CV_bins[i]) & (ccnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccnopi['weightSpline']\n",
    "        cccpi.loc[ (cccpi['nu_e'] > CV_bins[i-1]) & (cccpi['nu_e'] < CV_bins[i]) & (cccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * cccpi['weightSpline']\n",
    "        ncnopi.loc[ (ncnopi['nu_e'] > CV_bins[i-1]) & (ncnopi['nu_e'] < CV_bins[i]) & (ncnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncnopi['weightSpline']\n",
    "        nccpi.loc[ (nccpi['nu_e'] > CV_bins[i-1]) & (nccpi['nu_e'] < CV_bins[i]) & (nccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nccpi['weightSpline']\n",
    "        lee.loc[ (lee['nu_e'] > CV_bins[i-1]) & (lee['nu_e'] < CV_bins[i]) & (lee['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * lee['weightSpline']\n",
    "        dirt.loc[ (dirt['nu_e'] > CV_bins[i-1]) & (dirt['nu_e'] < CV_bins[i]) & (dirt['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * dirt['weightSpline']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "#df_v = [lee,mc,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    # and the 2d angle difference\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])\n",
    "    #df['anglediff_V'] = np.abs(df['secondshower_V_dir']-df['shrclusdir1'])\n",
    "    #df['anglediff_U'] = np.abs(df['secondshower_U_dir']-df['shrclusdir0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df['shr_tkfit_nhits_tot'] = (df['shr_tkfit_nhits_Y']+df['shr_tkfit_nhits_U']+df['shr_tkfit_nhits_V'])\n",
    "    df['shr_tkfit_dedx_avg'] = (df['shr_tkfit_nhits_Y']*df['shr_tkfit_dedx_Y'] + df['shr_tkfit_nhits_U']*df['shr_tkfit_dedx_U'] + df['shr_tkfit_nhits_V']*df['shr_tkfit_dedx_V'])/df['shr_tkfit_nhits_tot']\n",
    "    df['shr_tkfit_2cm_nhits_tot'] = (df['shr_tkfit_2cm_nhits_Y']+df['shr_tkfit_2cm_nhits_U']+df['shr_tkfit_2cm_nhits_V'])\n",
    "    df['shr_tkfit_2cm_dedx_avg'] = (df['shr_tkfit_2cm_nhits_Y']*df['shr_tkfit_2cm_dedx_Y'] + df['shr_tkfit_2cm_nhits_U']*df['shr_tkfit_2cm_dedx_U'] + df['shr_tkfit_2cm_nhits_V']*df['shr_tkfit_2cm_dedx_V'])/df['shr_tkfit_2cm_nhits_tot']\n",
    "    df['shr_tkfit_gap10_nhits_tot'] = (df['shr_tkfit_gap10_nhits_Y']+df['shr_tkfit_gap10_nhits_U']+df['shr_tkfit_gap10_nhits_V'])\n",
    "    df['shr_tkfit_gap10_dedx_avg'] = (df['shr_tkfit_gap10_nhits_Y']*df['shr_tkfit_gap10_dedx_Y'] + df['shr_tkfit_gap10_nhits_U']*df['shr_tkfit_gap10_dedx_U'] + df['shr_tkfit_gap10_nhits_V']*df['shr_tkfit_gap10_dedx_V'])/df['shr_tkfit_gap10_nhits_tot']\n",
    "    df.loc[:,'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_nhits_U']>df['shr_tkfit_nhits_Y']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_Y']) & (df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_U']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERCEPT = 0.0\n",
    "SLOPE = 0.83\n",
    "\n",
    "# define some energy-related variables\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"reco_e\"] = (df[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + df[\"trk_energy_tot\"]\n",
    "    df[\"reco_e_qe\"] = 0.938*((df[\"shr_energy\"]+INTERCEPT)/SLOPE)/(0.938 - ((df[\"shr_energy\"]+INTERCEPT)/SLOPE)*(1-np.cos(df[\"shr_theta\"])))\n",
    "    df[\"reco_e_rqe\"] = df[\"reco_e_qe\"]/df[\"reco_e\"]\n",
    "\n",
    "# and a way to filter out data\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"bnbdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "    df[\"extdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "data[\"bnbdata\"] = np.ones_like(data[\"shr_energy\"])\n",
    "ext[\"extdata\"] = np.ones_like(ext[\"shr_energy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double-counting of events out of FV in the NC/CC pi0 samples\n",
    "# not needed anymore since we improved matching with filtered samples\n",
    "#ncpi0 = ncpi0.query('category != 5')\n",
    "#ccpi0 = ccpi0.query('category != 5')\n",
    "#ccnopi = ccnopi.query('category != 5')\n",
    "#nccpi = nccpi.query('category != 5')\n",
    "#ncnopi = ncnopi.query('category != 5')\n",
    "\n",
    "## avoid recycling unbiased ext events (i.e. selecting a slice with little nu content from these samples)\n",
    "ccnopi = ccnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "cccpi = cccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "ncnopi = ncnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "nccpi = nccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "\n",
    "# add back the cosmic category, for background only\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to be trained on\n",
    "TRAINVAR = [\"shr_score\",\"tksh_distance\",\"tksh_angle\",\n",
    "            \"shr_tkfit_dedx_max\",\n",
    "            \"trkfit\",\"trkpid\",\n",
    "            \"subcluster\",\"shrmoliereavg\",\n",
    "            \"trkshrhitdist2\",\"hits_ratio\",\n",
    "            \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"anglediff_Y\",\n",
    "            \"CosmicIPAll3D\",\"CosmicDirAll3D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcI43ileYJ9P"
   },
   "outputs": [],
   "source": [
    "LABELS =  ['pi0','nonpi0']\n",
    "#LABELS =  [\"bkg\"]\n",
    "\n",
    "if (USEBDT == True):\n",
    "    for label, bkg_query in zip(LABELS, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'booster_%s_0304_extnumi.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            mc[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(mc[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nue[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nue[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ext[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ext[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            data[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(data[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            dirt[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(dirt[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            lee[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(lee[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            cccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(cccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    \"ncpi0\": ncpi0,\n",
    "    \"ccpi0\": ccpi0,\n",
    "    \"ccnopi\": ccnopi,\n",
    "    \"cccpi\": cccpi,\n",
    "    \"ncnopi\": ncnopi,\n",
    "    \"nccpi\": nccpi,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "#scaling = 101.0/4.21 #0218\n",
    "# scaling = 101.0/4.84 #0304\n",
    "#scaling = 69.6/4.84 #0304\n",
    "#scaling = 125.0/4.84 #0304\n",
    "scaling = 1\n",
    "\n",
    "SPLIT = 1.0\n",
    "if (USEBDT == True):\n",
    "    SPLIT = 1.48\n",
    "\n",
    "#''' 0304\n",
    "weights = {\n",
    "    \"mc\": 1.61e-01 * scaling, \n",
    "    \"ext\": 5.01e-01 * scaling, \n",
    "    \"nue\": 3.32e-03 * scaling,\n",
    "    \"lee\": 3.32e-03 * scaling,\n",
    "    \"dirt\": 9.09e-01 * scaling,\n",
    "    \"ncpi0\": 1.19e-01 * scaling,\n",
    "    \"ccpi0\": 5.92e-02 * SPLIT * scaling,\n",
    "    \"ncnopi\": 5.60e-02 * scaling,\n",
    "    \"nccpi\": 2.58e-02 * scaling,\n",
    "    \"ccnopi\": 6.48e-02 * scaling,\n",
    "    \"cccpi\": 5.18e-02 * scaling,\n",
    "}\n",
    "pot = 5.88e20*scaling\n",
    "\n",
    "my_plotter = plotter.Plotter(samples, weights, pot=pot)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unblinding_far_sideband import *\n",
    "from scipy.stats import poisson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#studies showing agreement between data and MC stats (w/ confidence intervals) vs. cut value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# studies showing agreement between data and MC stats (w/ confidence intervals) vs. cut value\n",
    "\n",
    "# thruth-cut on MC sample to avoid double counting with truth-filters (i.e. ccpi0, ncpi0, cccpi, ...)\n",
    "NU_Q = \"~(abs(nu_pdg) == 12 & ccnc == 0)\"\n",
    "NU_Q += \" & ~(mcf_np0==1 & mcf_nmp==0 & mcf_nmm==0 & mcf_nem==0 & mcf_nep==0)\"\n",
    "NU_Q += \" & ~(mcf_pass_ccpi0==1)\"\n",
    "NU_Q += \" & ~(mcf_pass_ccnopi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_ncnopi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_cccpi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_nccpi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "\n",
    "def GetNumEvents(VAR,EMIN,EMAX,QUERY):\n",
    "\n",
    "    TOT  = 0.\n",
    "    DATA = 0.\n",
    "    \n",
    "    for key, sample in samples.items():\n",
    "        THISQUERY = QUERY\n",
    "        # calculate weight for sample\n",
    "        #print (THISQUERY)\n",
    "        weight = 1\n",
    "        if (key != 'data'):\n",
    "            weight = weights[key]    \n",
    "        if (key == 'mc'):\n",
    "            THISQUERY += ' and %s'%NU_Q\n",
    "        # calculate bare entries\n",
    "        dfsub = sample.query(THISQUERY)\n",
    "        vals_v = dfsub[VAR].values\n",
    "        weights_v = np.ones(len(vals_v)) * weight\n",
    "        if ((key != 'data') and (key != 'ext')):\n",
    "            weights_v = dfsub['weightSplineTimesTune'].values * weight\n",
    "        v,be = np.histogram(vals_v,bins=np.array([EMIN,EMAX]),weights=weights_v)\n",
    "        \n",
    "        #print ('sample %s has %i entries'%(key,v[0]))\n",
    "\n",
    "        if (key == 'data'):\n",
    "            DATA += v[0]\n",
    "        else:\n",
    "            TOT += v[0]\n",
    "            \n",
    "    #print ('DATA : %.01f. EXPECTATION : %.01f'%(DATA,TOT))\n",
    "    # poisson interval\n",
    "    # 68%\n",
    "    range68 = poisson.interval(0.68,TOT)\n",
    "    range95 = poisson.interval(0.95,TOT)\n",
    "    range99 = poisson.interval(0.99,TOT)\n",
    "    #print ('range 68%% %.02f -- %.02f'%(range68[0],range68[1]))\n",
    "    #print ('range 95%% %.02f -- %.02f'%(range95[0],range95[1]))\n",
    "    return DATA,TOT,range68[0],range68[1],range95[0],range95[1],range99[0],range99[1]\n",
    "\n",
    "BDTCUT_V = np.concatenate((np.linspace(0.0,0.5,21),np.linspace(0.5,1.0,15)),axis=0)\n",
    "#BDTCU\n",
    "DATA_V = []\n",
    "EXP_V = []\n",
    "MIN68_V = []\n",
    "MAX68_V = []\n",
    "MIN95_V = []\n",
    "MAX95_V = []\n",
    "MIN99_V = []\n",
    "MAX99_V = []\n",
    "\n",
    "#GetNumEvents('reco_e',0.05,0.85,NPPRESQ+' and pi0_score > 0.7 and category!=111 and n_showers_contained == 1')\n",
    "\n",
    "#'''\n",
    "for BDTCUT in BDTCUT_V:\n",
    "    #print ('BDT cut : %.02f'%BDTCUT)\n",
    "    Q = stages_queries[1]\n",
    "    #print (Q)\n",
    "    Q += ' and nonpi0_score > %.02f and pi0_score < 1.0 and category != 111'%BDTCUT\n",
    "    d,e,m68,M68,m95,M95,m99,M99 = GetNumEvents('reco_e',1.05,2.05,Q)\n",
    "    DATA_V.append(d)\n",
    "    EXP_V.append(e)\n",
    "    MIN68_V.append(m68)\n",
    "    MAX68_V.append(M68)\n",
    "    MIN95_V.append(m95)\n",
    "    MAX95_V.append(M95)\n",
    "    MIN99_V.append(m99)\n",
    "    MAX99_V.append(M99)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.fill_between(BDTCUT_V,MIN99_V,MAX99_V,alpha=0.2,color='c',label='99% interval')\n",
    "plt.fill_between(BDTCUT_V,MIN95_V,MAX95_V,alpha=0.2,color='b',label='95% interval')\n",
    "plt.fill_between(BDTCUT_V,MIN68_V,MAX68_V,alpha=0.2,color='m',label='68% interval')\n",
    "\n",
    "plt.plot(BDTCUT_V,DATA_V,color='r',lw=2,label='observation')\n",
    "plt.plot(BDTCUT_V,EXP_V,color='b',lw=2,label='expectation')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('$\\pi^0$ BDT score cut')\n",
    "plt.ylabel('surviving events [%.02fE20 POT]'%(pot/1e20))\n",
    "plt.gca().ticklabel_format(scilimits=(-2,4))\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=1,fontsize=14)\n",
    "plt.show()\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 3\n",
    "no_data = False\n",
    "no_leg = True\n",
    "bins_reduction_factor = {\n",
    "    1: 1.0,\n",
    "    2: 0.5,\n",
    "    3: 0.5,\n",
    "    4: 0.5,\n",
    "    5: 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bdtcut in bdt_scan:\n",
    "    \n",
    "    print ('BDT cut value of %.01f'%bdtcut)\n",
    "    \n",
    "    if (bdtcut == 0.0):\n",
    "        break\n",
    "    for which_variables in plot_variables.keys():\n",
    "        this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "        if no_data:\n",
    "            this_folder += 'dry_run/bdtscan%02i/'%(int(bdtcut*10))\n",
    "        else:\n",
    "            this_folder += 'with_data/bdtscan%02i/'%(int(bdtcut*10))\n",
    "        this_folder += 'stage_{}/'.format(stage)\n",
    "        this_folder += (which_variables + '/')\n",
    "        !mkdir -p $this_folder\n",
    "\n",
    "        this_query = stages_queries[stage]\n",
    "        this_title = stages_titles[stage]\n",
    "        this_title += '\\n nonpi0_bdt > %.01f and Cosmic3D cuts'%bdtcut\n",
    "        \n",
    "        print (this_title)\n",
    "        \n",
    "        this_query += ' and CosmicDirAll3D > -0.98 and CosmicDirAll3D < 0.98'\n",
    "        this_query += ' and CosmicIPAll3D > 30'\n",
    "        this_query += ' and nonpi0_score > %.01f'%bdtcut\n",
    "\n",
    "        if no_data:\n",
    "            this_query += ' and bnbdata==0'\n",
    "\n",
    "        #print(which_variables)\n",
    "        this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "        for VARIABLE, BINS, RANGE, XTIT in this_plot_variables:\n",
    "            #print(VARIABLE, BINS, RANGE, XTIT)\n",
    "            fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "                VARIABLE,   \n",
    "                query=this_query,\n",
    "                kind=\"event_category\",\n",
    "                draw_sys=False,\n",
    "                stacksort=3,\n",
    "                title=XTIT,\n",
    "                bins=int(BINS*bins_reduction_factor[stage]),\n",
    "                range=RANGE,\n",
    "            )[0:3]\n",
    "            if 'score' in VARIABLE:\n",
    "                ax1.set_yscale('log')\n",
    "            else:\n",
    "                ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "            ax1.set_title(this_title, loc='left')\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(this_folder+VARIABLE+'.png', dpi=250)    \n",
    "    #         fig.savefig(this_folder+VARIABLE+'.pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_set = []\n",
    "#variables_set.append('insensitive_variables')\n",
    "#variables_set.append('input_bdt')\n",
    "#variables_set.append('bdt_scores')\n",
    "#variables_set.append('vlvars')\n",
    "variables_set.append('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_variables in variables_set:\n",
    "    this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "    if no_data:\n",
    "        this_folder += 'dry_run/'\n",
    "    else:\n",
    "        this_folder += 'with_data/'\n",
    "    this_folder += 'stage_{}/'.format(stage)\n",
    "    this_folder += (which_variables + '/')\n",
    "    !mkdir -p $this_folder\n",
    "    \n",
    "    this_query = stages_queries[stage]\n",
    "    this_title = stages_titles[stage]\n",
    "\n",
    "    if no_data:\n",
    "        this_query += ' and bnbdata==0'\n",
    "    \n",
    "    print(which_variables)\n",
    "    this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "    for VARIABLE, BINS, RANGE, XTIT in this_plot_variables:\n",
    "        print(VARIABLE, BINS, RANGE, XTIT)\n",
    "        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "            VARIABLE,   \n",
    "            query=this_query,\n",
    "            kind=\"event_category\",\n",
    "            draw_sys=True,\n",
    "            stacksort=3,\n",
    "            title=XTIT,\n",
    "            bins=BINS,#*bins_reduction_factor[stage],\n",
    "            range=RANGE,\n",
    "        )[0:3]\n",
    "        if 'score' in VARIABLE:\n",
    "            ax1.set_yscale('log')\n",
    "        else:\n",
    "            ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "        ax1.set_title(this_title, loc='left')\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(this_folder+VARIABLE+'.png', dpi=250)    \n",
    "#         fig.savefig(this_folder+VARIABLE+'.pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(HIGH_ENERGY+' and '+NPPRESEQ_one_shower_one_track+' and '+BDTCQ)[['run','sub','evt','reco_e','secondshower_Y_nhit','shrmoliereavg','shr_tkfit_nhits_tot','trk_score','trkshrhitdist0','trkshrhitdist1','trkshrhitdist2','shr_theta','subcluster','trk_len','trkpid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All stage together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_set = []\n",
    "variables_set.append('insensitive_variables')\n",
    "variables_set.append('input_bdt')\n",
    "variables_set.append('bdt_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data = False\n",
    "bins_reduction_factor = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 0.5,\n",
    "    4: 0.5,\n",
    "    5: 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in range(1, 6):\n",
    "    for which_variables in plot_variables.keys():\n",
    "        this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "        if no_data:\n",
    "            this_folder += 'dry_run/'\n",
    "        else:\n",
    "            this_folder += 'with_data/'\n",
    "        this_folder += 'stage_{}/'.format(stage)\n",
    "        this_folder += (which_variables + '/')\n",
    "        !mkdir -p $this_folder\n",
    "\n",
    "        this_query = stages_queries[stage]\n",
    "        this_title = stages_titles[stage]\n",
    "\n",
    "        if no_data:\n",
    "            this_query += ' and bnbdata==0'\n",
    "\n",
    "        print(which_variables)\n",
    "        this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "        for VARIABLE, BINS, RANGE, XTIT in this_plot_variables:\n",
    "            print(VARIABLE, BINS, RANGE, XTIT)\n",
    "            fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "                VARIABLE,   \n",
    "                query=this_query,\n",
    "                kind=\"event_category\",\n",
    "                draw_sys=False,\n",
    "                stacksort=3,\n",
    "                title=XTIT,\n",
    "                bins=int(BINS*bins_reduction_factor[stage]),\n",
    "                range=RANGE,\n",
    "            )[0:3]\n",
    "            if 'score' in VARIABLE:\n",
    "                ax1.set_yscale('log')\n",
    "            else:\n",
    "                ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "            ax1.set_title(this_title, loc='left')\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(this_folder+VARIABLE+'.png', dpi=250)    \n",
    "    #         fig.savefig(this_folder+VARIABLE+'.pdf')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All stage together with pi0 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unblinding_far_sideband import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_set = []\n",
    "# variables_set.append('insensitive_variables')\n",
    "# variables_set.append('input_bdt')\n",
    "variables_set.append('bdt_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data = False\n",
    "no_leg = False\n",
    "bins_reduction_factor = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 0.5,\n",
    "    4: 2,\n",
    "    5: 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in [1]:\n",
    "    for which_variables in variables_set:\n",
    "        this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "        this_folder += 'with_pi0_scaling/'\n",
    "        this_folder += 'stage_{}/'.format(stage)\n",
    "        this_folder += (which_variables + '/')\n",
    "        !mkdir -p $this_folder\n",
    "\n",
    "        this_query = stages_queries[stage]\n",
    "        this_title = stages_titles[stage] + '\\n' + r'$\\pi^0$ scaled by 0.759'\n",
    "\n",
    "        if no_data:\n",
    "            this_query += ' and bnbdata==0'\n",
    "\n",
    "        print(which_variables)\n",
    "        this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "        for VARIABLE, BINS, RANGE, XTIT in this_plot_variables:\n",
    "            print(VARIABLE, BINS, RANGE, XTIT)\n",
    "            out = my_plotter.plot_variable(\n",
    "                VARIABLE,   \n",
    "                query=this_query,\n",
    "                kind=\"event_category\",\n",
    "                draw_sys=True,\n",
    "                stacksort=3,\n",
    "                title=XTIT,\n",
    "                bins=int(BINS*bins_reduction_factor[stage]),\n",
    "                range=RANGE,\n",
    "            )\n",
    "            fig, ax1, ax2 = out[0:3]\n",
    "            \n",
    "            if no_leg:\n",
    "                ax1.legend().set_visible(False) \n",
    "            else:\n",
    "                ax1.set_title(this_title, loc='left')\n",
    "                ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            save_path = this_folder+VARIABLE\n",
    "            if no_leg:\n",
    "                save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "    #         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots with systematic uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedx after very loose box cuts\n",
    "detsys = {\n",
    "    'nue': [       0, 0.79671758, 0.34827979, 0.321645,   0.40333879, 0.1853362,\n",
    " 0.24609908, 0.33585692, 0.26870701, 0.40225343, 0.50266717, 0.65527298,\n",
    " 1.24068308, 0.59963333, 0.73699676]\n",
    "}\n",
    "\n",
    "stage = 2\n",
    "no_leg = True\n",
    "this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "this_folder += 'with_pi0_scaling/'\n",
    "this_folder += 'stage_{}/'.format(stage)\n",
    "this_folder += (which_variables + '/')\n",
    "!mkdir -p $this_folder\n",
    "\n",
    "this_query = stages_queries[stage]\n",
    "this_title = stages_titles[stage] + '\\n' + r'$\\pi^0$ scaled by 0.759' + '\\nwith detector systematics'\n",
    "\n",
    "this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_dedx_max',15,(0,10),\"shr tkfit dE/dx (max, 0-4 cm) [MeV/cm]\"\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS*bins_reduction_factor[stage]),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = this_folder+VARIABLE\n",
    "if no_leg:\n",
    "    save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pi0 score after very loose box cuts\n",
    "detsys = {\n",
    "    'nue': np.array([0.14096838, 0.52125645, 0.30698031, 0.16230782, 0.20707762, 0.20503962,\n",
    " 0.4905541,  0.17894124, 0.21784577, 0.12043394])\n",
    "\n",
    "}\n",
    "\n",
    "stage = 2\n",
    "no_leg = True\n",
    "this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "this_folder += 'with_pi0_scaling/'\n",
    "this_folder += 'stage_{}/'.format(stage)\n",
    "this_folder += (which_variables + '/')\n",
    "!mkdir -p $this_folder\n",
    "\n",
    "this_query = stages_queries[stage]\n",
    "this_title = stages_titles[stage] + '\\n' + r'$\\pi^0$ scaled by 0.759' + '\\nwith detector systematics'\n",
    "\n",
    "this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'pi0_score',10,(0., 1),\"BDT $\\pi^0$ score\"\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS*bins_reduction_factor[stage]),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = this_folder+VARIABLE\n",
    "if no_leg:\n",
    "    save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedx after far energy\n",
    "detsys = {\n",
    "    'nue': [       0.0, 0.91611439, 0.59984853, 0.36909447, 0.33792165, 0.28304237,\n",
    " 0.33751168, 0.22135163, 0.29769619, 0.15383638, 0.23421376, 0.22867616,\n",
    " 0.37325692, 0.18749145, 0.19447481, 0.27023232, 0.30524752, 0.31487403,\n",
    " 0.3269046,  0.41923414, 0.31404011, 0.49550582, 0.69728428, 0.594751,\n",
    " 0.52312608]\n",
    "\n",
    "}\n",
    "\n",
    "stage = 1\n",
    "no_leg = True\n",
    "# this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "# this_folder += 'with_pi0_scaling/'\n",
    "# this_folder += 'stage_{}/'.format(stage)\n",
    "# !mkdir -p $this_folder\n",
    "\n",
    "this_query = stages_queries[stage]\n",
    "this_title = stages_titles[stage] + '\\n' + r'$\\pi^0$ scaled by 0.759' + '\\nwith detector systematics'\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_dedx_max',25,(0,10),\"shr tkfit dE/dx (max, 0-4 cm) [MeV/cm]\"\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS*bins_reduction_factor[stage]),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = this_folder+VARIABLE\n",
    "if no_leg:\n",
    "    save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedx after far energy\n",
    "detsys = {\n",
    "    'nue': [0.09027234, 0.08413832, 0.07560043, 0.09114168, 0.05486566, 0.2446849,\n",
    " 0.23054174, 0.46507027, 0.20827211, 0.45844788, 0.39172489, 0.40934926,\n",
    " 0.49517035, 0.77600138, 0.88587843, 1.43771866, 1.27976322, 0.86024124,\n",
    " 1.15451296, 1.09811053]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "stage = 1\n",
    "no_leg = True\n",
    "# this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "# this_folder += 'with_pi0_scaling/'\n",
    "# this_folder += 'stage_{}/'.format(stage)\n",
    "# !mkdir -p $this_folder\n",
    "\n",
    "this_query = stages_queries[stage]\n",
    "this_title = stages_titles[stage] + '\\n' + r'$\\pi^0$ scaled by 0.759' + '\\nwith detector systematics'\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'shrmoliereavg',20,(0,50),\"average Moliere angle [degrees]\"\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS*bins_reduction_factor[stage]),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = this_folder+VARIABLE\n",
    "if no_leg:\n",
    "    save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedx after far energy\n",
    "detsys = {\n",
    "    'nue': [0.05403331, 0.12645447, 0.12424552, 0.12682673, 0.08274685, 0.11693988,\n",
    "0.27228293, 0.13337103, 0.19497178, 0.1070512,\n",
    "]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "stage = 1\n",
    "no_leg = True\n",
    "# this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "# this_folder += 'with_pi0_scaling/'\n",
    "# this_folder += 'stage_{}/'.format(stage)\n",
    "# !mkdir -p $this_folder\n",
    "\n",
    "this_query = stages_queries[stage]\n",
    "this_title = stages_titles[stage] + '\\n' + r'$\\pi^0$ scaled by 0.759' + '\\nwith detector systematics'\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'pi0_score',10,(0., 1),\"BDT $\\pi^0$ score\"\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS*bins_reduction_factor[stage]),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "save_path = this_folder+VARIABLE\n",
    "if no_leg:\n",
    "    save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
